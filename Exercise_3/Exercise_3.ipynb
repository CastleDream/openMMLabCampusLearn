{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1.环境检测和安装"],"metadata":{"id":"SFSQBkDSbp8U"}},{"cell_type":"markdown","source":["## 1.1 cuda_11.8对应的\"mmcv==2.0.0\"有GPU内存问题"],"metadata":{"id":"QetzZZHbqMDE"}},{"cell_type":"code","source":["!nvcc -V\n","!gcc --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SgaTyL62btVE","outputId":"0f2fa84f-215c-4c28-cdeb-d6397e2fe019","executionInfo":{"status":"ok","timestamp":1686472215991,"user_tz":-480,"elapsed":910,"user":{"displayName":"黄珊","userId":"02346048459009599635"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n","gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n","Copyright (C) 2019 Free Software Foundation, Inc.\n","This is free software; see the source for copying conditions.  There is NO\n","warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n","\n"]}]},{"cell_type":"markdown","source":["1. 这个讲课的老师也是用的colab，\n","2. 即便我连接的运行时环境是cpu，但是这里也可以看到nvcc的输出信息，即：服务器其实全都安装了nvcc，只是无法使用GPU而已"],"metadata":{"id":"WncO3Uppb93C"}},{"cell_type":"markdown","source":["下面一直报错GPU out of memory，但是之前第一节课没有这个问题，都是类似的配置文件，数据集大小甚至比这个还要大一些。。\n","\n","因此怀疑是库这些的版本问题，以前的安装是：\n","```bash\n","!pwd\n","!pip install -U \"openmim==0.3.7\"\n","!mim install \"mmengine==0.7.1\"\n","!mim install \"mmcv==2.0.0\"\n","```"],"metadata":{"id":"tTeQL7F_pGxs"}},{"cell_type":"markdown","source":["## 1.1 修改为没有GPU内存泄漏问题的版本"],"metadata":{"id":"1iIW2_7XqEMN"}},{"cell_type":"code","source":["!pip3 install install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ppDLzEdspwUX","executionInfo":{"status":"ok","timestamp":1686475171811,"user_tz":-480,"elapsed":113892,"user":{"displayName":"黄珊","userId":"02346048459009599635"}},"outputId":"4dee83ca-6fa3-4aaa-9ebb-16979bf95ad4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n","Collecting install\n","  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n","Collecting torch==1.11.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (1637.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.12.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl (22.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==0.11.0+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0+cu113) (4.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0+cu113) (8.4.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0+cu113) (3.4)\n","Installing collected packages: torch, install, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.1+cu118\n","    Uninstalling torch-2.0.1+cu118:\n","      Successfully uninstalled torch-2.0.1+cu118\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.15.2+cu118\n","    Uninstalling torchvision-0.15.2+cu118:\n","      Successfully uninstalled torchvision-0.15.2+cu118\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.0.2+cu118\n","    Uninstalling torchaudio-2.0.2+cu118:\n","      Successfully uninstalled torchaudio-2.0.2+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.11.0+cu113 which is incompatible.\n","torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.11.0+cu113 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed install-1.3.5 torch-1.11.0+cu113 torchaudio-0.11.0+cu113 torchvision-0.12.0+cu113\n"]}]},{"cell_type":"code","source":["!pwd\n","!pip install -U openmim\n","!mim install 'mmcv==2.0.0rc4'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EbJvwjvOvQq_","executionInfo":{"status":"ok","timestamp":1686475194275,"user_tz":-480,"elapsed":22483,"user":{"displayName":"黄珊","userId":"02346048459009599635"}},"outputId":"5400bcde-6979-4e92-b3f4-e5e2451648a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openmim\n","  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.3)\n","Collecting colorama (from openmim)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting model-index (from openmim)\n","  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n","Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.27.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.3.4)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.8.10)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.4.3)\n","Collecting ordered-set (from model-index->openmim)\n","  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2022.7.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.22.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.4)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.14.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n","Installing collected packages: ordered-set, colorama, model-index, openmim\n","Successfully installed colorama-0.4.6 model-index-0.1.11 openmim-0.3.7 ordered-set-4.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.11.0/index.html\n","Collecting mmcv==2.0.0rc4\n","  Downloading https://download.openmmlab.com/mmcv/dist/cu113/torch1.11.0/mmcv-2.0.0rc4-cp310-cp310-manylinux1_x86_64.whl (45.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting addict (from mmcv==2.0.0rc4)\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Collecting mmengine>=0.2.0 (from mmcv==2.0.0rc4)\n","  Downloading mmengine-0.7.4-py3-none-any.whl (374 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.3/374.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0rc4) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0rc4) (23.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0rc4) (8.4.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0rc4) (6.0)\n","Collecting yapf (from mmcv==2.0.0rc4)\n","  Downloading yapf-0.33.0-py2.py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.9/200.9 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv==2.0.0rc4) (4.7.0.72)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.2.0->mmcv==2.0.0rc4) (3.7.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.2.0->mmcv==2.0.0rc4) (13.3.4)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.2.0->mmcv==2.0.0rc4) (2.3.0)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==2.0.0rc4) (2.0.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (2.8.2)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.2.0->mmcv==2.0.0rc4) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.2.0->mmcv==2.0.0rc4) (2.14.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->mmengine>=0.2.0->mmcv==2.0.0rc4) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (1.16.0)\n","Installing collected packages: addict, yapf, mmengine, mmcv\n","Successfully installed addict-2.4.0 mmcv-2.0.0rc4 mmengine-0.7.4 yapf-0.33.0\n"]}]},{"cell_type":"code","source":["!mim install mmengine\n","!pip install opencv-python pillow matplotlib seaborn tqdm pycocotools -i https://pypi.tuna.tsinghua.edu.cn/simple"],"metadata":{"id":"JCe2gsrjb0Dj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f49a653-d1f3-478b-be65-c873659d108c","executionInfo":{"status":"ok","timestamp":1686475211097,"user_tz":-480,"elapsed":16840,"user":{"displayName":"黄珊","userId":"02346048459009599635"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.11.0/index.html\n","Requirement already satisfied: mmengine in /usr/local/lib/python3.10/dist-packages (0.7.4)\n","Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine) (1.22.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine) (6.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine) (13.3.4)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.3.0)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmengine) (0.33.0)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine) (4.7.0.72)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (2.8.2)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.14.0)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (2.0.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->mmengine) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\n","Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (2.0.6)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"]}]},{"cell_type":"code","source":["!mim install \"mmdet>=3.0.0rc6\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vgq8awVGuyr9","executionInfo":{"status":"ok","timestamp":1686475225971,"user_tz":-480,"elapsed":14881,"user":{"displayName":"黄珊","userId":"02346048459009599635"}},"outputId":"5c0f1d70-a354-4e1d-b62d-05a979f350ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.11.0/index.html\n","Collecting mmdet>=3.0.0rc6\n","  Downloading mmdet-3.0.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet>=3.0.0rc6) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet>=3.0.0rc6) (1.22.4)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet>=3.0.0rc6) (2.0.6)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet>=3.0.0rc6) (1.10.1)\n","Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet>=3.0.0rc6) (2.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet>=3.0.0rc6) (1.16.0)\n","Collecting terminaltables (from mmdet>=3.0.0rc6)\n","  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: mmcv<2.1.0,>=2.0.0rc4 in /usr/local/lib/python3.10/dist-packages (from mmdet>=3.0.0rc6) (2.0.0rc4)\n","Requirement already satisfied: mmengine<1.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from mmdet>=3.0.0rc6) (0.7.4)\n","Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4->mmdet>=3.0.0rc6) (2.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4->mmdet>=3.0.0rc6) (23.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4->mmdet>=3.0.0rc6) (8.4.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4->mmdet>=3.0.0rc6) (6.0)\n","Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4->mmdet>=3.0.0rc6) (0.33.0)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv<2.1.0,>=2.0.0rc4->mmdet>=3.0.0rc6) (4.7.0.72)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.7.1->mmdet>=3.0.0rc6) (13.3.4)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.7.1->mmdet>=3.0.0rc6) (2.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet>=3.0.0rc6) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet>=3.0.0rc6) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet>=3.0.0rc6) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet>=3.0.0rc6) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet>=3.0.0rc6) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet>=3.0.0rc6) (2.8.2)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.0.0,>=0.7.1->mmdet>=3.0.0rc6) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.0.0,>=0.7.1->mmdet>=3.0.0rc6) (2.14.0)\n","Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.1.0,>=2.0.0rc4->mmdet>=3.0.0rc6) (2.0.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->mmengine<1.0.0,>=0.7.1->mmdet>=3.0.0rc6) (0.1.2)\n","Installing collected packages: terminaltables, mmdet\n","Successfully installed mmdet-3.0.0 terminaltables-3.1.10\n"]}]},{"cell_type":"code","source":["!rm -rf mmdetection\n","!git clone -b 3.x https://github.com/open-mmlab/mmdetection.git \n","# %cd mmdetection\n","# %pip install -e ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TC10rqWEc_ft","outputId":"38aa8633-9fd8-4702-9bbb-9077f747beb4","executionInfo":{"status":"ok","timestamp":1686475249907,"user_tz":-480,"elapsed":5492,"user":{"displayName":"黄珊","userId":"02346048459009599635"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mmdetection'...\n","remote: Enumerating objects: 36605, done.\u001b[K\n","remote: Counting objects: 100% (1256/1256), done.\u001b[K\n","remote: Compressing objects: 100% (701/701), done.\u001b[K\n","remote: Total 36605 (delta 694), reused 920 (delta 541), pack-reused 35349\u001b[K\n","Receiving objects: 100% (36605/36605), 56.85 MiB | 21.67 MiB/s, done.\n","Resolving deltas: 100% (25629/25629), done.\n"]}]},{"cell_type":"markdown","source":["如果出现环境方面的问题，可以用下面的代码打印出log，贴到issue中去，方便定位错误\n","+ 这里提示 mmdet3.x 要配 mmcv>=2.0.0rc4, <2.1.0"],"metadata":{"id":"uFGXNgTDdrwH"}},{"cell_type":"code","source":["from mmengine.utils import get_git_hash\n","from mmengine.utils.dl_utils import collect_env as collect_base_env\n","\n","import mmdet\n","\n","\n","def collect_env():\n","    \"\"\"Collect the information of the running environments.\"\"\"\n","    env_info = collect_base_env()\n","    env_info['MMDetection'] = f'{mmdet.__version__}+{get_git_hash()[:7]}'\n","    return env_info\n","\n","\n","if __name__ == '__main__':\n","    for name, val in collect_env().items():\n","        print(f'{name}: {val}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yyGNcYlodE_W","outputId":"c6920498-7499-4216-fff0-254e69ad4f8d","executionInfo":{"status":"ok","timestamp":1686475234082,"user_tz":-480,"elapsed":3795,"user":{"displayName":"黄珊","userId":"02346048459009599635"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sys.platform: linux\n","Python: 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0]\n","CUDA available: True\n","numpy_random_seed: 2147483648\n","GPU 0: Tesla T4\n","CUDA_HOME: /usr/local/cuda\n","NVCC: Cuda compilation tools, release 11.8, V11.8.89\n","GCC: x86_64-linux-gnu-gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n","PyTorch: 1.11.0+cu113\n","PyTorch compiling details: PyTorch built with:\n","  - GCC 7.3\n","  - C++ Version: 201402\n","  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - LAPACK is enabled (usually provided by MKL)\n","  - NNPACK is enabled\n","  - CPU capability usage: AVX2\n","  - CUDA Runtime 11.3\n","  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n","  - CuDNN 8.2\n","  - Magma 2.5.2\n","  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n","\n","TorchVision: 0.12.0+cu113\n","OpenCV: 4.7.0\n","MMEngine: 0.7.4\n","MMDetection: 3.0.0+\n"]}]},{"cell_type":"markdown","source":["# 2.准备数据及数据可视化"],"metadata":{"id":"KeHpsjvEeYd4"}},{"cell_type":"markdown","source":["+ 这是一个社区贡献的猫咪目标检测图像数据集，144张\n","+ 可以看到是coco数据集的格式\n","\n",">由于目标检测大部分都是COCO格式的数据集，所以自己在制作数据集的时候，也建议使用COCO的格式，这样会有很多配套的工具，会比较方便"],"metadata":{"id":"QijUGLemf-5n"}},{"cell_type":"code","source":["!rm -rf cat_dataset*\n","%cd /content\n","!wget https://download.openmmlab.com/mmyolo/data/cat_dataset.zip\n","!unzip cat_dataset.zip -d cat_dataset && rm cat_dataset.zip"],"metadata":{"id":"lSxnWxtXd8u7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c0da6737-0079-4236-81b8-886a3f2bb85d","executionInfo":{"status":"ok","timestamp":1686475268228,"user_tz":-480,"elapsed":9601,"user":{"displayName":"黄珊","userId":"02346048459009599635"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","--2023-06-11 09:20:58--  https://download.openmmlab.com/mmyolo/data/cat_dataset.zip\n","Resolving download.openmmlab.com (download.openmmlab.com)... 8.48.85.209, 8.48.85.210, 8.48.85.211, ...\n","Connecting to download.openmmlab.com (download.openmmlab.com)|8.48.85.209|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 227204484 (217M) [application/zip]\n","Saving to: ‘cat_dataset.zip’\n","\n","cat_dataset.zip     100%[===================>] 216.68M  33.6MB/s    in 6.8s    \n","\n","2023-06-11 09:21:05 (31.8 MB/s) - ‘cat_dataset.zip’ saved [227204484/227204484]\n","\n","Archive:  cat_dataset.zip\n","   creating: cat_dataset/annotations/\n","  inflating: cat_dataset/annotations/annotations_all.json  \n","  inflating: cat_dataset/annotations/test.json  \n","  inflating: cat_dataset/annotations/trainval.json  \n","  inflating: cat_dataset/class_with_id.txt  \n","   creating: cat_dataset/images/\n","  inflating: cat_dataset/images/IMG_20210627_225110.jpg  \n","  inflating: cat_dataset/images/IMG_20210705_084125__01.jpg  \n","  inflating: cat_dataset/images/IMG_20210713_213907.jpg  \n","  inflating: cat_dataset/images/IMG_20210716_183123-02.jpeg  \n","  inflating: cat_dataset/images/IMG_20210718_213435.jpg  \n","  inflating: cat_dataset/images/IMG_20210725_193921.jpg  \n","  inflating: cat_dataset/images/IMG_20210726_161004.jpg  \n","  inflating: cat_dataset/images/IMG_20210726_161009.jpg  \n","  inflating: cat_dataset/images/IMG_20210727_213236.jpg  \n","  inflating: cat_dataset/images/IMG_20210728_205117.jpg  \n","  inflating: cat_dataset/images/IMG_20210728_205126.jpg  \n","  inflating: cat_dataset/images/IMG_20210728_205231.jpg  \n","  inflating: cat_dataset/images/IMG_20210728_205312.jpg  \n","  inflating: cat_dataset/images/IMG_20210728_205442.jpg  \n","  inflating: cat_dataset/images/IMG_20210728_225308.jpg  \n","  inflating: cat_dataset/images/IMG_20210729_203618.jpg  \n","  inflating: cat_dataset/images/IMG_20210730_202718.jpg  \n","  inflating: cat_dataset/images/IMG_20210821_225104.jpg  \n","  inflating: cat_dataset/images/IMG_20210821_225117.jpg  \n","  inflating: cat_dataset/images/IMG_20211008_172642.jpg  \n","  inflating: cat_dataset/images/IMG_20211008_215322.jpg  \n","  inflating: cat_dataset/images/IMG_20211011_172256.jpg  \n","  inflating: cat_dataset/images/IMG_20211012_112749.jpg  \n","  inflating: cat_dataset/images/IMG_20211013_202331.jpg  \n","  inflating: cat_dataset/images/IMG_20211017_112219.jpg  \n","  inflating: cat_dataset/images/IMG_20211018_000402.jpg  \n","  inflating: cat_dataset/images/IMG_20211018_000535.jpg  \n","  inflating: cat_dataset/images/IMG_20211018_000540.jpg  \n","  inflating: cat_dataset/images/IMG_20211020_091410.jpg  \n","  inflating: cat_dataset/images/IMG_20211020_091507.jpg  \n","  inflating: cat_dataset/images/IMG_20211020_091815.jpg  \n","  inflating: cat_dataset/images/IMG_20211024_223313.jpg  \n","  inflating: cat_dataset/images/IMG_20211102_003429.jpg  \n","  inflating: cat_dataset/images/IMG_20211111_111018.jpg  \n","  inflating: cat_dataset/images/IMG_20211111_111024.jpg  \n","  inflating: cat_dataset/images/IMG_20211112_113444.jpg  \n","  inflating: cat_dataset/images/IMG_20211113_001351.jpg  \n","  inflating: cat_dataset/images/IMG_20211113_110820.jpg  \n","  inflating: cat_dataset/images/IMG_20211113_222118.jpg  \n","  inflating: cat_dataset/images/IMG_20211114_231757.jpg  \n","  inflating: cat_dataset/images/IMG_20211118_113532.jpg  \n","  inflating: cat_dataset/images/IMG_20211121_004001.jpg  \n","  inflating: cat_dataset/images/IMG_20211128_002541.jpg  \n","  inflating: cat_dataset/images/IMG_20211129_135920.jpg  \n","  inflating: cat_dataset/images/IMG_20211129_135923.jpg  \n","  inflating: cat_dataset/images/IMG_20211130_134238.jpg  \n","  inflating: cat_dataset/images/IMG_20211201_005251.jpg  \n","  inflating: cat_dataset/images/IMG_20211204_113858.jpg  \n","  inflating: cat_dataset/images/IMG_20211205_120730.jpg  \n","  inflating: cat_dataset/images/IMG_20211205_120756.jpg  \n","  inflating: cat_dataset/images/IMG_20211205_233848.jpg  \n","  inflating: cat_dataset/images/IMG_20211212_152325.jpg  \n","  inflating: cat_dataset/images/IMG_20211212_152327.jpg  \n","  inflating: cat_dataset/images/IMG_20211221_231337-01.jpeg  \n","  inflating: cat_dataset/images/IMG_20211222_232834.jpg  \n","  inflating: cat_dataset/images/IMG_20211223_111335.jpg  \n","  inflating: cat_dataset/images/IMG_20211223_113151.jpg  \n","  inflating: cat_dataset/images/IMG_20211226_111130.jpg  \n","  inflating: cat_dataset/images/IMG_20211226_145210.jpg  \n","  inflating: cat_dataset/images/IMG_20211226_145213.jpg  \n","  inflating: cat_dataset/images/IMG_20211229_114002.jpg  \n","  inflating: cat_dataset/images/IMG_20211229_114004.jpg  \n","  inflating: cat_dataset/images/IMG_20220101_102512.jpg  \n","  inflating: cat_dataset/images/IMG_20220102_145054.jpg  \n","  inflating: cat_dataset/images/IMG_20220102_145059.jpg  \n","  inflating: cat_dataset/images/IMG_20220104_093957.jpg  \n","  inflating: cat_dataset/images/IMG_20220105_114545.jpg  \n","  inflating: cat_dataset/images/IMG_20220108_113141.jpg  \n","  inflating: cat_dataset/images/IMG_20220113_000205.jpg  \n","  inflating: cat_dataset/images/IMG_20220116_231420.jpg  \n","  inflating: cat_dataset/images/IMG_20220121_002010.jpg  \n","  inflating: cat_dataset/images/IMG_20220129_115726.jpg  \n","  inflating: cat_dataset/images/IMG_20220129_115735.jpg  \n","  inflating: cat_dataset/images/IMG_20220129_115815.jpg  \n","  inflating: cat_dataset/images/IMG_20220218_174512.jpg  \n","  inflating: cat_dataset/images/IMG_20220220_090936.jpg  \n","  inflating: cat_dataset/images/IMG_20220226_153147.jpg  \n","  inflating: cat_dataset/images/IMG_20220226_153211.jpg  \n","  inflating: cat_dataset/images/IMG_20220227_092407.jpg  \n","  inflating: cat_dataset/images/IMG_20220304_175916.jpg  \n","  inflating: cat_dataset/images/IMG_20220426_000429.jpg  \n","  inflating: cat_dataset/images/IMG_20220501_175251.jpg  \n","  inflating: cat_dataset/images/IMG_20220521_102945.jpg  \n","  inflating: cat_dataset/images/IMG_20220522_234313.jpg  \n","  inflating: cat_dataset/images/IMG_20220526_231514.jpg  \n","  inflating: cat_dataset/images/IMG_20220529_105618.jpg  \n","  inflating: cat_dataset/images/IMG_20220708_001224.jpg  \n","  inflating: cat_dataset/images/IMG_20220708_180908.jpg  \n","  inflating: cat_dataset/images/IMG_20220714_172111.jpg  \n","  inflating: cat_dataset/images/IMG_20220716_170801.jpg  \n","  inflating: cat_dataset/images/IMG_20220717_004836.jpg  \n","  inflating: cat_dataset/images/IMG_20220717_005025.jpg  \n","  inflating: cat_dataset/images/IMG_20220717_005250.jpg  \n","  inflating: cat_dataset/images/IMG_20220717_005546.jpg  \n","  inflating: cat_dataset/images/IMG_20220722_004122.jpg  \n","  inflating: cat_dataset/images/IMG_20220729_164616.jpg  \n","  inflating: cat_dataset/images/IMG_20220729_164632.jpg  \n","  inflating: cat_dataset/images/IMG_20220731_000132.jpg  \n","  inflating: cat_dataset/images/IMG_20220731_000152.jpg  \n","  inflating: cat_dataset/images/IMG_20220731_000222.jpg  \n","  inflating: cat_dataset/images/IMG_20220801_003940.jpg  \n","  inflating: cat_dataset/images/IMG_20220801_121425.jpg  \n","  inflating: cat_dataset/images/IMG_20220806_163742.jpg  \n","  inflating: cat_dataset/images/IMG_20220810_001500.jpg  \n","  inflating: cat_dataset/images/IMG_20220810_001640.jpg  \n","  inflating: cat_dataset/images/IMG_20220810_002743.jpg  \n","  inflating: cat_dataset/images/IMG_20220811_000256.jpg  \n","  inflating: cat_dataset/images/IMG_20220821_002647.jpg  \n","  inflating: cat_dataset/images/IMG_20220906_143153.jpg  \n","  inflating: cat_dataset/images/IMG_20220906_180027.jpg  \n","  inflating: cat_dataset/images/IMG_20220907_174625.jpg  \n","  inflating: cat_dataset/images/IMG_20220910_180615.jpg  \n","  inflating: cat_dataset/images/IMG_20220910_180738.jpg  \n","  inflating: cat_dataset/images/IMG_20220911_233842.jpg  \n","  inflating: cat_dataset/images/IMG_20220915_081724.jpg  \n","  inflating: cat_dataset/images/IMG_20220916_160854.jpg  \n","  inflating: cat_dataset/images/IMG_20220919_132323.jpg  \n","  inflating: cat_dataset/images/IMG_20220925_213133.jpg  \n","  inflating: cat_dataset/images/IMG_20220928_000053.jpg  \n","  inflating: cat_dataset/images/IMG_20220928_000258.jpg  \n","  inflating: cat_dataset/images/IMG_20220928_113207.jpg  \n","  inflating: cat_dataset/images/IMG_20220928_113234.jpg  \n","  inflating: cat_dataset/images/IMG_20221004_121455.jpg  \n","  inflating: cat_dataset/images/IMG_20221004_121701.jpg  \n","  inflating: cat_dataset/images/IMG_20221004_121711.jpg  \n","  inflating: cat_dataset/images/IMG_20221006_111718.jpg  \n","  inflating: cat_dataset/images/IMG_20221006_155140.jpg  \n","  inflating: cat_dataset/images/IMG_20221006_155205.jpg  \n","  inflating: cat_dataset/images/IMG_20221006_155554.jpg  \n","  inflating: cat_dataset/images/IMG_20221010_001237.jpg  \n","  inflating: cat_dataset/images/IMG_20221010_235201.jpg  \n","  inflating: cat_dataset/images/IMG_20221019_114522.jpg  \n","  inflating: cat_dataset/images/IMG_20221020_112705.jpg  \n","  inflating: cat_dataset/images/IMG_20221021_113643.jpg  \n","  inflating: cat_dataset/images/IMG_20221024_004622.jpg  \n","  inflating: cat_dataset/images/IMG_20221024_233600.jpg  \n","  inflating: cat_dataset/images/IMG_20221108_152717.jpg  \n","  inflating: cat_dataset/images/IMG_20221109_111948.jpg  \n","  inflating: cat_dataset/images/IMG_20221110_085050.jpg  \n","  inflating: cat_dataset/images/mmexport1632412239895.jpg  \n","  inflating: cat_dataset/images/mmexport1633684751291.jpg  \n","  inflating: cat_dataset/images/mmexport1633684756766.jpg  \n","  inflating: cat_dataset/images/mmexport1633684900217.jpg  \n","  inflating: cat_dataset/images/mmexport1657713359667.jpg  \n","   creating: cat_dataset/labels/\n","  inflating: cat_dataset/labels/IMG_20210627_225110.json  \n","  inflating: cat_dataset/labels/IMG_20210705_084125__01.json  \n","  inflating: cat_dataset/labels/IMG_20210713_213907.json  \n","  inflating: cat_dataset/labels/IMG_20210716_183123-02.json  \n","  inflating: cat_dataset/labels/IMG_20210718_213435.json  \n","  inflating: cat_dataset/labels/IMG_20210725_193921.json  \n","  inflating: cat_dataset/labels/IMG_20210726_161004.json  \n","  inflating: cat_dataset/labels/IMG_20210726_161009.json  \n","  inflating: cat_dataset/labels/IMG_20210727_213236.json  \n","  inflating: cat_dataset/labels/IMG_20210728_205117.json  \n","  inflating: cat_dataset/labels/IMG_20210728_205126.json  \n","  inflating: cat_dataset/labels/IMG_20210728_205231.json  \n","  inflating: cat_dataset/labels/IMG_20210728_205312.json  \n","  inflating: cat_dataset/labels/IMG_20210728_205442.json  \n","  inflating: cat_dataset/labels/IMG_20210728_225308.json  \n","  inflating: cat_dataset/labels/IMG_20210729_203618.json  \n","  inflating: cat_dataset/labels/IMG_20210730_202718.json  \n","  inflating: cat_dataset/labels/IMG_20210821_225104.json  \n","  inflating: cat_dataset/labels/IMG_20210821_225117.json  \n","  inflating: cat_dataset/labels/IMG_20211008_172642.json  \n","  inflating: cat_dataset/labels/IMG_20211008_215322.json  \n","  inflating: cat_dataset/labels/IMG_20211011_172256.json  \n","  inflating: cat_dataset/labels/IMG_20211012_112749.json  \n","  inflating: cat_dataset/labels/IMG_20211013_202331.json  \n","  inflating: cat_dataset/labels/IMG_20211017_112219.json  \n","  inflating: cat_dataset/labels/IMG_20211018_000402.json  \n","  inflating: cat_dataset/labels/IMG_20211018_000535.json  \n","  inflating: cat_dataset/labels/IMG_20211018_000540.json  \n","  inflating: cat_dataset/labels/IMG_20211020_091410.json  \n","  inflating: cat_dataset/labels/IMG_20211020_091507.json  \n","  inflating: cat_dataset/labels/IMG_20211020_091815.json  \n","  inflating: cat_dataset/labels/IMG_20211024_223313.json  \n","  inflating: cat_dataset/labels/IMG_20211102_003429.json  \n","  inflating: cat_dataset/labels/IMG_20211111_111018.json  \n","  inflating: cat_dataset/labels/IMG_20211111_111024.json  \n","  inflating: cat_dataset/labels/IMG_20211112_113444.json  \n","  inflating: cat_dataset/labels/IMG_20211113_001351.json  \n","  inflating: cat_dataset/labels/IMG_20211113_110820.json  \n","  inflating: cat_dataset/labels/IMG_20211113_222118.json  \n","  inflating: cat_dataset/labels/IMG_20211114_231757.json  \n","  inflating: cat_dataset/labels/IMG_20211118_113532.json  \n","  inflating: cat_dataset/labels/IMG_20211121_004001.json  \n","  inflating: cat_dataset/labels/IMG_20211128_002541.json  \n","  inflating: cat_dataset/labels/IMG_20211129_135920.json  \n","  inflating: cat_dataset/labels/IMG_20211129_135923.json  \n","  inflating: cat_dataset/labels/IMG_20211130_134238.json  \n","  inflating: cat_dataset/labels/IMG_20211201_005251.json  \n","  inflating: cat_dataset/labels/IMG_20211204_113858.json  \n","  inflating: cat_dataset/labels/IMG_20211205_120730.json  \n","  inflating: cat_dataset/labels/IMG_20211205_120756.json  \n","  inflating: cat_dataset/labels/IMG_20211205_233848.json  \n","  inflating: cat_dataset/labels/IMG_20211212_152325.json  \n","  inflating: cat_dataset/labels/IMG_20211212_152327.json  \n","  inflating: cat_dataset/labels/IMG_20211221_231337-01.json  \n","  inflating: cat_dataset/labels/IMG_20211222_232834.json  \n","  inflating: cat_dataset/labels/IMG_20211223_111335.json  \n","  inflating: cat_dataset/labels/IMG_20211223_113151.json  \n","  inflating: cat_dataset/labels/IMG_20211226_111130.json  \n","  inflating: cat_dataset/labels/IMG_20211226_145210.json  \n","  inflating: cat_dataset/labels/IMG_20211226_145213.json  \n","  inflating: cat_dataset/labels/IMG_20211229_114002.json  \n","  inflating: cat_dataset/labels/IMG_20211229_114004.json  \n","  inflating: cat_dataset/labels/IMG_20220101_102512.json  \n","  inflating: cat_dataset/labels/IMG_20220102_145054.json  \n","  inflating: cat_dataset/labels/IMG_20220102_145059.json  \n","  inflating: cat_dataset/labels/IMG_20220104_093957.json  \n","  inflating: cat_dataset/labels/IMG_20220105_114545.json  \n","  inflating: cat_dataset/labels/IMG_20220108_113141.json  \n","  inflating: cat_dataset/labels/IMG_20220113_000205.json  \n","  inflating: cat_dataset/labels/IMG_20220116_231420.json  \n","  inflating: cat_dataset/labels/IMG_20220121_002010.json  \n","  inflating: cat_dataset/labels/IMG_20220129_115726.json  \n","  inflating: cat_dataset/labels/IMG_20220129_115735.json  \n","  inflating: cat_dataset/labels/IMG_20220129_115815.json  \n","  inflating: cat_dataset/labels/IMG_20220218_174512.json  \n","  inflating: cat_dataset/labels/IMG_20220220_090936.json  \n","  inflating: cat_dataset/labels/IMG_20220226_153147.json  \n","  inflating: cat_dataset/labels/IMG_20220226_153211.json  \n","  inflating: cat_dataset/labels/IMG_20220227_092407.json  \n","  inflating: cat_dataset/labels/IMG_20220304_175916.json  \n","  inflating: cat_dataset/labels/IMG_20220426_000429.json  \n","  inflating: cat_dataset/labels/IMG_20220501_175251.json  \n","  inflating: cat_dataset/labels/IMG_20220521_102945.json  \n","  inflating: cat_dataset/labels/IMG_20220522_234313.json  \n","  inflating: cat_dataset/labels/IMG_20220526_231514.json  \n","  inflating: cat_dataset/labels/IMG_20220529_105618.json  \n","  inflating: cat_dataset/labels/IMG_20220708_001224.json  \n","  inflating: cat_dataset/labels/IMG_20220708_180908.json  \n","  inflating: cat_dataset/labels/IMG_20220714_172111.json  \n","  inflating: cat_dataset/labels/IMG_20220716_170801.json  \n","  inflating: cat_dataset/labels/IMG_20220717_004836.json  \n","  inflating: cat_dataset/labels/IMG_20220717_005025.json  \n","  inflating: cat_dataset/labels/IMG_20220717_005250.json  \n","  inflating: cat_dataset/labels/IMG_20220717_005546.json  \n","  inflating: cat_dataset/labels/IMG_20220722_004122.json  \n","  inflating: cat_dataset/labels/IMG_20220729_164616.json  \n","  inflating: cat_dataset/labels/IMG_20220729_164632.json  \n","  inflating: cat_dataset/labels/IMG_20220731_000132.json  \n","  inflating: cat_dataset/labels/IMG_20220731_000152.json  \n","  inflating: cat_dataset/labels/IMG_20220731_000222.json  \n","  inflating: cat_dataset/labels/IMG_20220801_003940.json  \n","  inflating: cat_dataset/labels/IMG_20220801_121425.json  \n","  inflating: cat_dataset/labels/IMG_20220806_163742.json  \n","  inflating: cat_dataset/labels/IMG_20220810_001500.json  \n","  inflating: cat_dataset/labels/IMG_20220810_001640.json  \n","  inflating: cat_dataset/labels/IMG_20220810_002743.json  \n","  inflating: cat_dataset/labels/IMG_20220811_000256.json  \n","  inflating: cat_dataset/labels/IMG_20220821_002647.json  \n","  inflating: cat_dataset/labels/IMG_20220906_143153.json  \n","  inflating: cat_dataset/labels/IMG_20220906_180027.json  \n","  inflating: cat_dataset/labels/IMG_20220907_174625.json  \n","  inflating: cat_dataset/labels/IMG_20220910_180615.json  \n","  inflating: cat_dataset/labels/IMG_20220910_180738.json  \n","  inflating: cat_dataset/labels/IMG_20220911_233842.json  \n","  inflating: cat_dataset/labels/IMG_20220915_081724.json  \n","  inflating: cat_dataset/labels/IMG_20220916_160854.json  \n","  inflating: cat_dataset/labels/IMG_20220919_132323.json  \n","  inflating: cat_dataset/labels/IMG_20220925_213133.json  \n","  inflating: cat_dataset/labels/IMG_20220928_000053.json  \n","  inflating: cat_dataset/labels/IMG_20220928_000258.json  \n","  inflating: cat_dataset/labels/IMG_20220928_113207.json  \n","  inflating: cat_dataset/labels/IMG_20220928_113234.json  \n","  inflating: cat_dataset/labels/IMG_20221004_121455.json  \n","  inflating: cat_dataset/labels/IMG_20221004_121701.json  \n","  inflating: cat_dataset/labels/IMG_20221004_121711.json  \n","  inflating: cat_dataset/labels/IMG_20221006_111718.json  \n","  inflating: cat_dataset/labels/IMG_20221006_155140.json  \n","  inflating: cat_dataset/labels/IMG_20221006_155205.json  \n","  inflating: cat_dataset/labels/IMG_20221006_155554.json  \n","  inflating: cat_dataset/labels/IMG_20221010_001237.json  \n","  inflating: cat_dataset/labels/IMG_20221010_235201.json  \n","  inflating: cat_dataset/labels/IMG_20221019_114522.json  \n","  inflating: cat_dataset/labels/IMG_20221020_112705.json  \n","  inflating: cat_dataset/labels/IMG_20221021_113643.json  \n","  inflating: cat_dataset/labels/IMG_20221024_004622.json  \n","  inflating: cat_dataset/labels/IMG_20221024_233600.json  \n","  inflating: cat_dataset/labels/IMG_20221108_152717.json  \n","  inflating: cat_dataset/labels/IMG_20221109_111948.json  \n","  inflating: cat_dataset/labels/IMG_20221110_085050.json  \n","  inflating: cat_dataset/labels/mmexport1632412239895.json  \n","  inflating: cat_dataset/labels/mmexport1633684751291.json  \n","  inflating: cat_dataset/labels/mmexport1633684756766.json  \n","  inflating: cat_dataset/labels/mmexport1633684900217.json  \n","  inflating: cat_dataset/labels/mmexport1657713359667.json  \n"]}]},{"cell_type":"markdown","source":["## 2.1 交互式可视化方式1"],"metadata":{"id":"rzYI26xSiRY4"}},{"cell_type":"markdown","source":["需要进行可视化看一下，在这种交互式的环境里（服务器数据）\n","+ 刚好在这里试一下自己之前写的利用ipywidgets进行的交互式可视化查看\n","+ 可以成功，就是速度有点慢。。。（或者说。。相当慢。。），切换一张图需要12s。。。"],"metadata":{"id":"hKZYRaytgnVE"}},{"cell_type":"code","source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","from ipywidgets import interact\n","import cv2\n","\n","import glob\n","image_path = \"/content/cat_dataset/images\"\n","imgNameList=glob.glob(f'{image_path}/*.jpg')\n","\n","imgList=[]\n","for imgPath in imgNameList:\n","    img = cv2.imread(imgPath)\n","    imgList.append(img[:,:,(2,1,0)])\n","def browse_images(images):\n","    n = len(images)\n","    def view_image(i):\n","#         plt.imshow(images[i], cmap=plt.cm.gray_r, interpolation='nearest')\n","        plt.imshow(images[i])\n","        plt.show()\n","    interact(view_image, i=(0,n-1))\n","\n","browse_images(imgList)"],"metadata":{"id":"l5L8PajYf-WO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2 交互式可视化方式2"],"metadata":{"id":"PnfxGMk4iVN-"}},{"cell_type":"markdown","source":["会显示一个下拉框，让你选择要查看哪张图"],"metadata":{"id":"tCFG4hq9i-Ce"}},{"cell_type":"code","source":["from IPython.display import Image\n","import os\n","\n","import ipywidgets as widgets\n","from ipywidgets import interact, interact_manual\n","\n","@interact\n","def show_images(file=os.listdir(image_path)):\n","    imageFilePath = os.path.join(image_path,file)\n","    display(Image(imageFilePath))"],"metadata":{"id":"4UaM5qwxhsC7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3 可视化方式3（教程里的，普通的无交互式的）"],"metadata":{"id":"w6ZfSFUVjFHU"}},{"cell_type":"code","source":["import os\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","%matplotlib inline\n","%config InlineBackend.figure_format=\"retina\"\n","\n","original_images =[]\n","images =[]\n","texts=[]\n","plt.figure(figsize=(16,5))\n","\n","image_list = os.listdir(image_path)[:8]\n","\n","for i,filename in enumerate(image_list):\n","  name = os.path.splitext(filename)[0]\n","  \"\"\"\n","  splitext(p)\n","    Split the extension from a pathname.\n","    \n","    Extension is everything from the last dot to the end, ignoring\n","    leading dots.  Returns \"(root, ext)\"; ext may be empty.\n","  \"\"\"\n","  imageFilePath = os.path.join(image_path,filename)\n","  image = Image.open(imageFilePath).convert('RGB')\n","  plt.subplot(2,4,i+1)\n","  plt.imshow(image)\n","  plt.title(filename)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"TjtLQKaKigPQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["可以看到，这个数据集还是比较简单\n","+ 背景简单\n","+ 同时大部分图像里都只有1只猫"],"metadata":{"id":"DneTI36xqFmT"}},{"cell_type":"markdown","source":["## 2.4 COCO JSON标注可视化"],"metadata":{"id":"sIHO1W2mqUNN"}},{"cell_type":"markdown","source":["相关的代码其实很多，可以看看：\n","+ [Kaggle-COCO_Data_Visualization](https://www.kaggle.com/code/lplenka/coco-data-visualization)\n","+ <https://leimao.github.io/blog/Inspecting-COCO-Dataset-Using-COCO-API/>\n","+ [Detailed walkthrough of COCOAPI (via pycocotools)](https://gist.github.com/interactivetech/c2913317603b79c02ff49fa9824f1104)\n","\n","另外，这个脚本其实利用了图像在相机拍摄时的一些信息(EXIF)，详见：\n","+ <https://stackoverflow.com/questions/23064549/get-date-and-time-when-photo-was-taken-from-exif-data-using-pil>\n","+ <https://blog.csdn.net/mizhenpeng/article/details/82794112>"],"metadata":{"id":"Gcqv9z09rbCD"}},{"cell_type":"markdown","source":["这是用到的一些函数"],"metadata":{"id":"Z7iTAOcs72Tm"}},{"cell_type":"code","source":["from pycocotools.coco import COCO\n","import numpy as np\n","import os\n","from matplotlib.collections import PatchCollection\n","from matplotlib.patches import Polygon\n","\n","def apply_exif_orientation(image):\n","  \"\"\"\n","  exif: extra information 额外信息\n","  \"\"\"\n","  _EXIF_ORIENT =274\n","  if not hasattr(image,'getexif'):\n","    return image\n","  try:\n","    exif = image.getexif()\n","  except Exception:\n","    exif=None\n","    return image\n","  orientation = exif.get(_EXIF_ORIENT)\n","  method = {2:Image.FLIP_LEFT_RIGHT,\n","            3:Image.ROTATE_180,\n","            4:Image.FLIP_TOP_BOTTOM,\n","            5:Image.TRANSPOSE,\n","            6:Image.ROTATE_270,\n","            7:Image.TRANSVERSE,\n","            8:Image.ROTATE_90}.get(orientation)\n","  if method is not None:\n","    return image.transpose(method)\n","  return image\n","\n","def show_bbox_only(coco,anns,show_label_bbox=True,is_filling=True):\n","  \"\"\"Show bounding box of annotation Only\"\"\"\n","  if(len(anns)==0):\n","    return\n","  ax =plt.gca()\n","  ax.set_autoscale_on(False)\n","\n","  image2color = dict()\n","  for cat in coco.getCatIds():\n","    image2color[cat]=(np.random.random((1,3))*0.7+0.3).tolist()[0]\n","  \n","  polygons=[]\n","  colors=[]\n","\n","  for ann in anns:\n","    color = image2color[ann['category_id']]\n","    bbox_x,bbox_y,bbox_w,bbow_h = ann['bbox']\n","    # 构成多边形的顺时针\n","    # poly = [[bbox_x,bbox_y],[bbox_x+bbox_w,bbox_y],[bbox_x+bbox_w,bbox_y+bbow_h],[bbox_x,bbox_y+bbow_h]] \n","    # 逆时针\n","    poly = [[bbox_x,bbox_y],[bbox_x,bbox_y+bbow_h],[bbox_x+bbox_w,bbox_y+bbow_h],[bbox_x+bbox_w,bbox_y]]\n","    polygons.append(Polygon(np.array(poly).reshape((4,2))))\n","    colors.append(color)\n","    if show_label_bbox:\n","      label_box = dict(facecolor=color)\n","    else:\n","      label_box = None\n","    ax.text(bbox_x,bbox_y,f\"{coco.loadCats(ann['category_id'])[0]['name']}\",color='white',bbox=label_box)\n","  if is_filling:\n","    p=PatchCollection(polygons,facecolor=colors,linewidth=0,alpha=0.4)\n","    ax.add_collection(p)"],"metadata":{"id":"FAoYcBPGpJxp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 测试函数的一些片段\n","import numpy as np\n","(np.random.random((1,3))*0.7+0.3).tolist()[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ABQKeAd4sm6","outputId":"df2f298c-1042-44c4-808c-6de4d373d448"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.3759065973575756, 0.4292439437875001, 0.5524937984733429]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["调用上面的函数进行可视化"],"metadata":{"id":"kDngeY_A77LI"}},{"cell_type":"code","source":["import os\n","\n","json_base_path = '/content/cat_dataset/annotations/'\n","coco = COCO(os.path.join(json_base_path,'test.json'))\n","image_ids=coco.getImgIds()\n","np.random.shuffle(image_ids)\n","\n","plt.figure(figsize=(16,5))\n","for i in range(8):\n","  image_data=coco.loadImgs(image_ids[i])[0]\n","  image_file_path = os.path.join(\"/content/cat_dataset/images\",image_data[\"file_name\"])\n","  # print(image_file_path)\n","  annotation_ids = coco.getAnnIds(imgIds=image_data['id'],catIds=[],iscrowd=0)\n","  # print(f\"image_data['id'] = {image_data['id']}, image_ids[i] ={image_ids[i]}\")\n","  annotation = coco.loadAnns(annotation_ids)\n","\n","  ax=plt.subplot(2,4,i+1)\n","  image = Image.open(image_file_path).convert('RGB')\n"," \n","  # 这行代码很关键，否则可能图像和标签对不上\n","  image = apply_exif_orientation(image)\n","  # PIL读取的图像，有可能meta信息和图像的高宽是不对应的，用opencv读取就没有这个问题\n","  ax.imshow(image)\n","  show_bbox_only(coco,annotation)\n","  plt.title(image_data[\"file_name\"])\n","  plt.xticks([])\n","  plt.yticks([])\n","plt.tight_layout()"],"metadata":{"id":"JafO3w6J7yhO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(image_ids),image_ids[2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mDNjyvpd4toj","outputId":"4955de81-a938-46b3-8059-8e40aafe398f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'> 102\n"]}]},{"cell_type":"markdown","source":["# 3.cat自定义配置和训练"],"metadata":{"id":"mosq1cWXBSnc"}},{"cell_type":"markdown","source":["## 3.1 RTMDet介绍\n","\n","下图源自：<https://mmyolo.readthedocs.io/zh_CN/latest/recommended_topics/algorithm_descriptions/rtmdet_description.html>\n","\n","```bash\n","![img](https://user-images.githubusercontent.com/27466624/204126145-cb4ff4f1-fb16-455e-96b5-17620081023a.jpg)\n","```"],"metadata":{"id":"0e0d_QZ_B00A"}},{"cell_type":"markdown","source":["以下表格是直接复制网页，然后让chatGPT生成markdown脚本的\n","+ RTMDet是以YoloX为基础，加上了一些优化得到的\n","+ 效果变好了，但是速度没怎么变（加了东西但是没变慢）\n","\n","|| mAP | Params         | Flops          | Inference speed |\n","|:---| :---| :-------------| :-------------| :--------------|\n","| Baseline(YOLOX)          | 40.2           | 9M             | 13.4G          | 1.2ms          |\n","| + AdamW + Flat Cosine    | 40.6 (+0.4)    | 9M             | 13.4G          | 1.2ms          |\n","| + CSPNeXt backbone & PAFPN | 41.8 (+1.2) |10.07M (+1.07)| 14.8G (+1.4)  | 1.22ms (+0.02)|\n","| + SepBNHead              | 41.8 (+0)      | 8.89M (-1.18) | 14.8G          | 1.22ms         |\n","| + Label Assign & Loss    | 42.9 (+1.1)    | 8.89M         | 14.8G          | 1.22ms         |\n","| + Cached Mosaic & MixUp  | 44.2 (+1.3)    | 8.89M         | 14.8G          | 1.22ms         |\n","| + RSB-pretrained backbone | 44.5 (+0.3)   | 8.89M         | 14.8G          | 1.22ms         |\n"],"metadata":{"id":"YuNbJ4JAJSO5"}},{"cell_type":"markdown","source":["## 3.2 挂载文件准备保存"],"metadata":{"id":"5cNHOCbJ42mv"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubyutHKV41UZ","outputId":"0bc6829e-d4d6-4872-f1ee-52da606a76b6","executionInfo":{"status":"ok","timestamp":1686475292211,"user_tz":-480,"elapsed":18274,"user":{"displayName":"黄珊","userId":"02346048459009599635"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## 3.3 配置文件修改"],"metadata":{"id":"kK5tb8qTLhgi"}},{"cell_type":"markdown","source":["这里的cat数据集是一个单类数据集，默认的mmdetection的配置是针对coco的，有80类，所以需要进行一些修改"],"metadata":{"id":"MywgxGfDLkX7"}},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjrIMUZ_MdxS","outputId":"fa0f2586-507d-40c3-f932-c0dafd7fa7a9","executionInfo":{"status":"ok","timestamp":1686475268617,"user_tz":-480,"elapsed":393,"user":{"displayName":"黄珊","userId":"02346048459009599635"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"markdown","source":["**注意**：\n","+ 配置好文件之后在可视化的部分，`dataset = DATASETS.build(cfg.train_dataloader.dataset)`这句代码\n","+ 一直报错说 Cocodataset找不到路径'/annotations/trainval.json'\n","+ 这里拼接好像不是os.path.join\n","  + 之前`data_root = '/content/cat_dataset/'`和`ann_file='/annotations/trainval.json'`\n","  + 改成`data_root = '/content/cat_dataset'`和`ann_file='annotations/trainval.json'`就不报错了。。。\n","  + 这里的路径拼接好扯淡啊，需要把多余的`/`给删掉。。。osp是os.path的缩写吗。。"],"metadata":{"id":"pj1Yr_XHH3Px"}},{"cell_type":"code","source":["config_cat = \"\"\"\n","# 把一些常用的配置参数放在前面，下面去引用这些常量即可，修改会比较方便\n","_base_='/content/mmdetection/configs/rtmdet/rtmdet-ins_tiny_8xb32-300e_coco.py'\n","\n","train_batch_size_per_gpu=32\n","train_num_workers=2\n","\n","val_batch_size_per_gpu=4\n","val_num_workers=2\n","\n","num_classes=1\n","\n","# 由于数据集小，同时训练epoch次数少，可以把backbone固定，RTMDet的backbone就4个stage，所以下面frozen_stage=4就是全部固定（不是从0开始，就是1 2 3 4），可以看看上面的图或者论文\n","# 只让模型去学head部分，做下游任务的适配即可\n","model =dict(\n","  backbone = dict(frozen_stages=4),\n","  bbox_head=dict(dict(num_classes=num_classes))\n",")\n","\n","# 学习率随着batchsize改变,0.04是8卡x32（每个卡的batchsize=32）的学习率,\n","# 12是这里设置的train_batch_size_per_gpu，\n","# 所以学习率要根据卡数和batchsize数（也就是计算梯度loss时实际使用的数据量）\n","# 0.04/(32*8)就是纯纯训练一个数据的学习率\n","base_lr = train_batch_size_per_gpu*0.04/(32*8)\n","\n","# RTMDet训练过程分为两个Stage，第二个过程会切换数据增强pipeline，第二阶段的epoch次数是5\n","# max_epochs=40，也就是前35个是一套数据增强，最后5个是一套数据增强，两阶段\n","max_epochs=40\n","num_epochs_stage2=5\n","\n","# 这个预训练模型组织方式和mmpretrain不一样，需要在github对应网络的readme里找，\n","# https://github.com/open-mmlab/mmdetection/tree/main/configs/rtmdet\n","# finetune 用之前训练好的预训练权重\n","load_from = 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet-ins_tiny_8xb32-300e_coco/rtmdet-ins_tiny_8xb32-300e_coco_20221130_151727-ec670f7e.pth'\n","\n","# 数据集改变了，则train_loader那些也要变\n","data_root = '/content/cat_dataset'\n","\n","# metainfo这个字段在mmdetection2.0没有，3.0里才有，而且只包含两个字段，\n","# classes就是类别，palette就是对这个类进行可视化的时候用的颜色，也是为了方便调节吧，所以抽出来了\n","# 注意：classes是一个tuple，所以即使只有一个类，也应该写成`cat,`\n","metainfo={\n","  'classes':('cat',),\n","  'palette':[(220,20,60),]\n","}\n","\n","train_dataloader = dict(\n","    batch_size=train_batch_size_per_gpu,\n","    num_workers=train_num_workers,\n","    pin_memory=True,\n","    dataset=dict(\n","        data_root=data_root,\n","        metainfo=metainfo,\n","        data_prefix=dict(img='images/'),\n","        ann_file='annotations/trainval.json'\n","    )\n",")\n","\n","val_dataloader = dict(\n","    batch_size=val_batch_size_per_gpu,\n","    num_workers=val_num_workers,\n","    dataset=dict(\n","        data_root=data_root,\n","        metainfo=metainfo,\n","        data_prefix=dict(img='images/'),\n","        ann_file='annotations/test.json'\n","   )\n",")\n","\n","test_dataloader = val_dataloader\n","\n","# 默认的学习率调度器是warmup 1000，但是cat数据集太小了，需要修改为30 iter\n","param_scheduler = [\n","    dict(\n","        type='LinearLR',\n","        start_factor=1.0e-5,\n","        by_epoch=False,\n","        begin=0,\n","        end=30),\n","    dict(\n","        # use cosine lr from 10 to 20 epoch\n","        type='CosineAnnealingLR',\n","        eta_min=base_lr * 0.05,\n","        begin=max_epochs // 2,  #max_epoch也需要改变\n","        end=max_epochs,\n","        T_max=max_epochs // 2,\n","        by_epoch=True,\n","        convert_to_iter_based=True),\n","]\n","optim_wrapper = dict(optimizer=dict(lr=base_lr))\n","\n","# 第二stage切换pipeline的epoch也变了\n","_base_.custom_hooks[1].switch_epoch = max_epochs-num_epochs_stage2\n","\n","val_evaluator = dict(ann_file=data_root + '/annotations/test.json')\n","test_evaluator=val_evaluator\n","\n","# 打印设置\n","default_hooks = dict(\n","    checkpoint=dict(interval=10,max_keep_ckpts=2, save_best='auto'),\n","    logger=dict(type='LoggerHook', interval=5))\n","train_cfg= dict(max_epochs=max_epochs, val_interval=10)\n","\n","\"\"\""],"metadata":{"id":"Myb0RrJE9ERe","executionInfo":{"status":"ok","timestamp":1686489393579,"user_tz":-480,"elapsed":361,"user":{"displayName":"黄珊","userId":"02346048459009599635"}}},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":["注意：\n","1. 自定义数据集最重要的是`metainfo`字段，用户在配置完成后要记得将其传给dataset配置，否则不生效。有些用户在自定义数据集时喜欢直接去修改coco.py源码，这个是强烈不推荐的做法，正确做法是配置metainfo将其传给dataset\n","2. 如果metainfo配置不正确，通常会出现以下几种情况：\n","  1. 出现num_classes不匹配错误\n","  2. loss_bbox始终为0\n","  3. 出现训练后评估结果为空等典型情况\n","3. mmdetection提供的学习率大部分是基于8卡的，如果总batchsize（bs）不同，一定要记得缩放学习率，否则有些算法很容易出现NAN，详见：[学习率自动缩放](https://mmdetection.readthedocs.io/zh_CN/latest/user_guides/train.html#id3)"],"metadata":{"id":"DAgxrhUu8KI7"}},{"cell_type":"code","source":["# rtmdet-ins_tiny_8xb32-300e_coco.py 这里的命名规则 8是8卡， b32是batchsize=32,300e是300epoch\n","with open('/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_cat.py','w') as f:\n","  f.write(config_cat)"],"metadata":{"id":"u_d_D1zw46is","executionInfo":{"status":"ok","timestamp":1686489398136,"user_tz":-480,"elapsed":444,"user":{"displayName":"黄珊","userId":"02346048459009599635"}}},"execution_count":112,"outputs":[]},{"cell_type":"markdown","source":["## 3.4 训练前可视化验证"],"metadata":{"id":"rl7GtUF_9wJB"}},{"cell_type":"markdown","source":["+ 可以采用mmdet提供的[`tools/analysis_tools/browse_dataset.py`](https://github.com/open-mmlab/mmdetection/blob/main/tools/analysis_tools/browse_dataset.py)脚本来对训练前的dataloader进行可视化，确保数据部分没有问题\n","+ 确保配置.py文件没有语法问题\n","+ 可视化前几张图就可以，因此基于browse_dataset.py脚本实现一个简易的就行"],"metadata":{"id":"lK7N8VNy-ShR"}},{"cell_type":"code","source":["from mmdet.registry import DATASETS,VISUALIZERS\n","from mmengine.config import Config\n","from mmengine.registry import init_default_scope\n","import os\n","import matplotlib.pyplot as plt\n","\n","cat_config_path = '/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_cat.py'\n","cfg =Config.fromfile(cat_config_path)\n","init_default_scope(cfg.get('default_scope','mmdet'))\n","\n","dataset = DATASETS.build(cfg.train_dataloader.dataset)\n","visualizer = VISUALIZERS.build(cfg.visualizer)\n","visualizer.dataset_meta = dataset.metainfo\n","\n","plt.figure(figsize=(16,5))\n","\n","for i in range(8):\n","  item = dataset[i]\n","  img = item['inputs'].permute(1,2,0).numpy()\n","  data_sample = item['data_samples'].numpy()\n","  gt_instances=data_sample.gt_instances\n","  img_path = os.path.basename(item['data_samples'].img_path)\n","\n","  gt_bboxes=gt_instances.get('bboxes',None)\n","  gt_instances.bboxes = gt_bboxes.tensor\n","  data_sample.gt_instances=gt_instances\n","\n","  visualizer.add_datasample(\n","            os.path.basename(img_path),\n","            img,\n","            data_sample,\n","            draw_gt=True,\n","            draw_pred=False,\n","            show=False)\n","  drawed_image= visualizer.get_image()\n","  plt.subplot(2,4,i+1)\n","  plt.imshow(drawed_image[...,[2,1,0]])\n","  plt.title(f'{os.path.basename(img_path)}')\n","  plt.xticks([])\n","  plt.yticks([])\n","plt.tight_layout()"],"metadata":{"id":"yesb7I-o5yAR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["这里画出的结果是数字增强之后的，所以有的图看起来很奇怪，\n","+ 有的两只猫叠在一起了\n","+ 有的图像是多个图拼接的"],"metadata":{"id":"GuE55Fs6K5dJ"}},{"cell_type":"markdown","source":["## 3.5 训练"],"metadata":{"id":"c8P1RDT1RFJR"}},{"cell_type":"code","source":["import torch\n","torch.cuda.empty_cache()\n","\n","import os\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""],"metadata":{"id":"EgM8YHztShss","executionInfo":{"status":"ok","timestamp":1686489402863,"user_tz":-480,"elapsed":495,"user":{"displayName":"黄珊","userId":"02346048459009599635"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["!python /content/mmdetection/tools/train.py \\\n","'/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_cat.py'\\\n","--work-dir '/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat'"],"metadata":{"id":"NhBhbziiA-wI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686489789949,"user_tz":-480,"elapsed":386584,"user":{"displayName":"黄珊","userId":"02346048459009599635"}},"outputId":"1ba132cd-84a2-4274-9cd2-5976c6bbf17e"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["06/11 13:16:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n","------------------------------------------------------------\n","System environment:\n","    sys.platform: linux\n","    Python: 3.10.12 (main, Jun  7 2023, 12:45:35) [GCC 9.4.0]\n","    CUDA available: True\n","    numpy_random_seed: 60600211\n","    GPU 0: Tesla T4\n","    CUDA_HOME: /usr/local/cuda\n","    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n","    GCC: x86_64-linux-gnu-gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n","    PyTorch: 1.11.0+cu113\n","    PyTorch compiling details: PyTorch built with:\n","  - GCC 7.3\n","  - C++ Version: 201402\n","  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - LAPACK is enabled (usually provided by MKL)\n","  - NNPACK is enabled\n","  - CPU capability usage: AVX2\n","  - CUDA Runtime 11.3\n","  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n","  - CuDNN 8.2\n","  - Magma 2.5.2\n","  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n","\n","    TorchVision: 0.12.0+cu113\n","    OpenCV: 4.7.0\n","    MMEngine: 0.7.4\n","\n","Runtime environment:\n","    cudnn_benchmark: False\n","    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n","    dist_cfg: {'backend': 'nccl'}\n","    seed: 60600211\n","    Distributed launcher: none\n","    Distributed training: False\n","    GPU number: 1\n","------------------------------------------------------------\n","\n","06/11 13:16:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n","default_scope = 'mmdet'\n","default_hooks = dict(\n","    timer=dict(type='IterTimerHook'),\n","    logger=dict(type='LoggerHook', interval=5),\n","    param_scheduler=dict(type='ParamSchedulerHook'),\n","    checkpoint=dict(\n","        type='CheckpointHook', interval=10, max_keep_ckpts=2,\n","        save_best='auto'),\n","    sampler_seed=dict(type='DistSamplerSeedHook'),\n","    visualization=dict(type='DetVisualizationHook'))\n","env_cfg = dict(\n","    cudnn_benchmark=False,\n","    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n","    dist_cfg=dict(backend='nccl'))\n","vis_backends = [dict(type='LocalVisBackend')]\n","visualizer = dict(\n","    type='DetLocalVisualizer',\n","    vis_backends=[dict(type='LocalVisBackend')],\n","    name='visualizer')\n","log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)\n","log_level = 'INFO'\n","load_from = 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet-ins_tiny_8xb32-300e_coco/rtmdet-ins_tiny_8xb32-300e_coco_20221130_151727-ec670f7e.pth'\n","resume = False\n","train_cfg = dict(\n","    type='EpochBasedTrainLoop',\n","    max_epochs=40,\n","    val_interval=10,\n","    dynamic_intervals=[(280, 1)])\n","val_cfg = dict(type='ValLoop')\n","test_cfg = dict(type='TestLoop')\n","param_scheduler = [\n","    dict(type='LinearLR', start_factor=1e-05, by_epoch=False, begin=0, end=30),\n","    dict(\n","        type='CosineAnnealingLR',\n","        eta_min=0.00025,\n","        begin=20,\n","        end=40,\n","        T_max=20,\n","        by_epoch=True,\n","        convert_to_iter_based=True)\n","]\n","optim_wrapper = dict(\n","    type='OptimWrapper',\n","    optimizer=dict(type='AdamW', lr=0.005, weight_decay=0.05),\n","    paramwise_cfg=dict(\n","        norm_decay_mult=0, bias_decay_mult=0, bypass_duplicate=True))\n","auto_scale_lr = dict(enable=False, base_batch_size=16)\n","dataset_type = 'CocoDataset'\n","data_root = '/content/cat_dataset'\n","backend_args = None\n","train_pipeline = [\n","    dict(type='LoadImageFromFile', backend_args=None),\n","    dict(\n","        type='LoadAnnotations',\n","        with_bbox=True,\n","        with_mask=True,\n","        poly2mask=False),\n","    dict(\n","        type='CachedMosaic',\n","        img_scale=(640, 640),\n","        pad_val=114.0,\n","        max_cached_images=20,\n","        random_pop=False),\n","    dict(\n","        type='RandomResize',\n","        scale=(1280, 1280),\n","        ratio_range=(0.5, 2.0),\n","        keep_ratio=True),\n","    dict(type='RandomCrop', crop_size=(640, 640)),\n","    dict(type='YOLOXHSVRandomAug'),\n","    dict(type='RandomFlip', prob=0.5),\n","    dict(type='Pad', size=(640, 640), pad_val=dict(img=(114, 114, 114))),\n","    dict(\n","        type='CachedMixUp',\n","        img_scale=(640, 640),\n","        ratio_range=(1.0, 1.0),\n","        max_cached_images=10,\n","        random_pop=False,\n","        pad_val=(114, 114, 114),\n","        prob=0.5),\n","    dict(type='FilterAnnotations', min_gt_bbox_wh=(1, 1)),\n","    dict(type='PackDetInputs')\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile', backend_args=None),\n","    dict(type='Resize', scale=(640, 640), keep_ratio=True),\n","    dict(type='Pad', size=(640, 640), pad_val=dict(img=(114, 114, 114))),\n","    dict(\n","        type='PackDetInputs',\n","        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n","                   'scale_factor'))\n","]\n","train_dataloader = dict(\n","    batch_size=32,\n","    num_workers=2,\n","    persistent_workers=True,\n","    sampler=dict(type='DefaultSampler', shuffle=True),\n","    batch_sampler=None,\n","    dataset=dict(\n","        type='CocoDataset',\n","        data_root='/content/cat_dataset',\n","        ann_file='annotations/trainval.json',\n","        data_prefix=dict(img='images/'),\n","        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n","        pipeline=[\n","            dict(type='LoadImageFromFile', backend_args=None),\n","            dict(\n","                type='LoadAnnotations',\n","                with_bbox=True,\n","                with_mask=True,\n","                poly2mask=False),\n","            dict(\n","                type='CachedMosaic',\n","                img_scale=(640, 640),\n","                pad_val=114.0,\n","                max_cached_images=20,\n","                random_pop=False),\n","            dict(\n","                type='RandomResize',\n","                scale=(1280, 1280),\n","                ratio_range=(0.5, 2.0),\n","                keep_ratio=True),\n","            dict(type='RandomCrop', crop_size=(640, 640)),\n","            dict(type='YOLOXHSVRandomAug'),\n","            dict(type='RandomFlip', prob=0.5),\n","            dict(\n","                type='Pad', size=(640, 640),\n","                pad_val=dict(img=(114, 114, 114))),\n","            dict(\n","                type='CachedMixUp',\n","                img_scale=(640, 640),\n","                ratio_range=(1.0, 1.0),\n","                max_cached_images=10,\n","                random_pop=False,\n","                pad_val=(114, 114, 114),\n","                prob=0.5),\n","            dict(type='FilterAnnotations', min_gt_bbox_wh=(1, 1)),\n","            dict(type='PackDetInputs')\n","        ],\n","        backend_args=None,\n","        metainfo=dict(classes=('cat', ), palette=[(220, 20, 60)])),\n","    pin_memory=True)\n","val_dataloader = dict(\n","    batch_size=4,\n","    num_workers=2,\n","    persistent_workers=True,\n","    drop_last=False,\n","    sampler=dict(type='DefaultSampler', shuffle=False),\n","    dataset=dict(\n","        type='CocoDataset',\n","        data_root='/content/cat_dataset',\n","        ann_file='annotations/test.json',\n","        data_prefix=dict(img='images/'),\n","        test_mode=True,\n","        pipeline=[\n","            dict(type='LoadImageFromFile', backend_args=None),\n","            dict(type='Resize', scale=(640, 640), keep_ratio=True),\n","            dict(\n","                type='Pad', size=(640, 640),\n","                pad_val=dict(img=(114, 114, 114))),\n","            dict(\n","                type='PackDetInputs',\n","                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n","                           'scale_factor'))\n","        ],\n","        backend_args=None,\n","        metainfo=dict(classes=('cat', ), palette=[(220, 20, 60)])))\n","test_dataloader = dict(\n","    batch_size=4,\n","    num_workers=2,\n","    persistent_workers=True,\n","    drop_last=False,\n","    sampler=dict(type='DefaultSampler', shuffle=False),\n","    dataset=dict(\n","        type='CocoDataset',\n","        data_root='/content/cat_dataset',\n","        ann_file='annotations/test.json',\n","        data_prefix=dict(img='images/'),\n","        test_mode=True,\n","        pipeline=[\n","            dict(type='LoadImageFromFile', backend_args=None),\n","            dict(type='Resize', scale=(640, 640), keep_ratio=True),\n","            dict(\n","                type='Pad', size=(640, 640),\n","                pad_val=dict(img=(114, 114, 114))),\n","            dict(\n","                type='PackDetInputs',\n","                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n","                           'scale_factor'))\n","        ],\n","        backend_args=None,\n","        metainfo=dict(classes=('cat', ), palette=[(220, 20, 60)])))\n","val_evaluator = dict(\n","    type='CocoMetric',\n","    ann_file='/content/cat_dataset/annotations/test.json',\n","    metric=['bbox', 'segm'],\n","    format_only=False,\n","    backend_args=None,\n","    proposal_nums=(100, 1, 10))\n","test_evaluator = dict(\n","    type='CocoMetric',\n","    ann_file='/content/cat_dataset/annotations/test.json',\n","    metric=['bbox', 'segm'],\n","    format_only=False,\n","    backend_args=None,\n","    proposal_nums=(100, 1, 10))\n","tta_model = dict(\n","    type='DetTTAModel',\n","    tta_cfg=dict(nms=dict(type='nms', iou_threshold=0.6), max_per_img=100))\n","img_scales = [(640, 640), (320, 320), (960, 960)]\n","tta_pipeline = [\n","    dict(type='LoadImageFromFile', backend_args=None),\n","    dict(\n","        type='TestTimeAug',\n","        transforms=[[{\n","            'type': 'Resize',\n","            'scale': (640, 640),\n","            'keep_ratio': True\n","        }, {\n","            'type': 'Resize',\n","            'scale': (320, 320),\n","            'keep_ratio': True\n","        }, {\n","            'type': 'Resize',\n","            'scale': (960, 960),\n","            'keep_ratio': True\n","        }],\n","                    [{\n","                        'type': 'RandomFlip',\n","                        'prob': 1.0\n","                    }, {\n","                        'type': 'RandomFlip',\n","                        'prob': 0.0\n","                    }],\n","                    [{\n","                        'type': 'Pad',\n","                        'size': (960, 960),\n","                        'pad_val': {\n","                            'img': (114, 114, 114)\n","                        }\n","                    }],\n","                    [{\n","                        'type':\n","                        'PackDetInputs',\n","                        'meta_keys':\n","                        ('img_id', 'img_path', 'ori_shape', 'img_shape',\n","                         'scale_factor', 'flip', 'flip_direction')\n","                    }]])\n","]\n","model = dict(\n","    type='RTMDet',\n","    data_preprocessor=dict(\n","        type='DetDataPreprocessor',\n","        mean=[103.53, 116.28, 123.675],\n","        std=[57.375, 57.12, 58.395],\n","        bgr_to_rgb=False,\n","        batch_augments=None),\n","    backbone=dict(\n","        type='CSPNeXt',\n","        arch='P5',\n","        expand_ratio=0.5,\n","        deepen_factor=0.167,\n","        widen_factor=0.375,\n","        channel_attention=True,\n","        norm_cfg=dict(type='SyncBN'),\n","        act_cfg=dict(type='SiLU', inplace=True),\n","        init_cfg=dict(\n","            type='Pretrained',\n","            prefix='backbone.',\n","            checkpoint=\n","            'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth'\n","        ),\n","        frozen_stages=4),\n","    neck=dict(\n","        type='CSPNeXtPAFPN',\n","        in_channels=[96, 192, 384],\n","        out_channels=96,\n","        num_csp_blocks=1,\n","        expand_ratio=0.5,\n","        norm_cfg=dict(type='SyncBN'),\n","        act_cfg=dict(type='SiLU', inplace=True)),\n","    bbox_head=dict(\n","        type='RTMDetInsSepBNHead',\n","        num_classes=1,\n","        in_channels=96,\n","        stacked_convs=2,\n","        share_conv=True,\n","        pred_kernel_size=1,\n","        feat_channels=96,\n","        act_cfg=dict(type='SiLU', inplace=True),\n","        norm_cfg=dict(type='SyncBN', requires_grad=True),\n","        anchor_generator=dict(\n","            type='MlvlPointGenerator', offset=0, strides=[8, 16, 32]),\n","        bbox_coder=dict(type='DistancePointBBoxCoder'),\n","        loss_cls=dict(\n","            type='QualityFocalLoss',\n","            use_sigmoid=True,\n","            beta=2.0,\n","            loss_weight=1.0),\n","        loss_bbox=dict(type='GIoULoss', loss_weight=2.0),\n","        loss_mask=dict(\n","            type='DiceLoss', loss_weight=2.0, eps=5e-06, reduction='mean')),\n","    train_cfg=dict(\n","        assigner=dict(type='DynamicSoftLabelAssigner', topk=13),\n","        allowed_border=-1,\n","        pos_weight=-1,\n","        debug=False),\n","    test_cfg=dict(\n","        nms_pre=1000,\n","        min_bbox_size=0,\n","        score_thr=0.05,\n","        nms=dict(type='nms', iou_threshold=0.6),\n","        max_per_img=100,\n","        mask_thr_binary=0.5))\n","train_pipeline_stage2 = [\n","    dict(type='LoadImageFromFile', backend_args=None),\n","    dict(\n","        type='LoadAnnotations',\n","        with_bbox=True,\n","        with_mask=True,\n","        poly2mask=False),\n","    dict(\n","        type='RandomResize',\n","        scale=(640, 640),\n","        ratio_range=(0.5, 2.0),\n","        keep_ratio=True),\n","    dict(\n","        type='RandomCrop',\n","        crop_size=(640, 640),\n","        recompute_bbox=True,\n","        allow_negative_crop=True),\n","    dict(type='FilterAnnotations', min_gt_bbox_wh=(1, 1)),\n","    dict(type='YOLOXHSVRandomAug'),\n","    dict(type='RandomFlip', prob=0.5),\n","    dict(type='Pad', size=(640, 640), pad_val=dict(img=(114, 114, 114))),\n","    dict(type='PackDetInputs')\n","]\n","max_epochs = 40\n","stage2_num_epochs = 20\n","base_lr = 0.005\n","interval = 10\n","custom_hooks = [\n","    dict(\n","        type='EMAHook',\n","        ema_type='ExpMomentumEMA',\n","        momentum=0.0002,\n","        update_buffers=True,\n","        priority=49),\n","    dict(\n","        type='PipelineSwitchHook',\n","        switch_epoch=35,\n","        switch_pipeline=[\n","            dict(type='LoadImageFromFile', backend_args=None),\n","            dict(\n","                type='LoadAnnotations',\n","                with_bbox=True,\n","                with_mask=True,\n","                poly2mask=False),\n","            dict(\n","                type='RandomResize',\n","                scale=(640, 640),\n","                ratio_range=(0.5, 2.0),\n","                keep_ratio=True),\n","            dict(\n","                type='RandomCrop',\n","                crop_size=(640, 640),\n","                recompute_bbox=True,\n","                allow_negative_crop=True),\n","            dict(type='FilterAnnotations', min_gt_bbox_wh=(1, 1)),\n","            dict(type='YOLOXHSVRandomAug'),\n","            dict(type='RandomFlip', prob=0.5),\n","            dict(\n","                type='Pad', size=(640, 640),\n","                pad_val=dict(img=(114, 114, 114))),\n","            dict(type='PackDetInputs')\n","        ])\n","]\n","checkpoint = 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth'\n","train_batch_size_per_gpu = 32\n","train_num_workers = 2\n","val_batch_size_per_gpu = 4\n","val_num_workers = 2\n","num_classes = 1\n","num_epochs_stage2 = 5\n","metainfo = dict(classes=('cat', ), palette=[(220, 20, 60)])\n","launcher = 'none'\n","work_dir = '/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat'\n","\n","06/11 13:16:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n","06/11 13:16:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(49          ) EMAHook                            \n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","after_load_checkpoint:\n","(49          ) EMAHook                            \n"," -------------------- \n","before_train:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(49          ) EMAHook                            \n","(NORMAL      ) IterTimerHook                      \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n","(NORMAL      ) DistSamplerSeedHook                \n","(NORMAL      ) PipelineSwitchHook                 \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","after_train_iter:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(49          ) EMAHook                            \n","(NORMAL      ) IterTimerHook                      \n","(BELOW_NORMAL) LoggerHook                         \n","(LOW         ) ParamSchedulerHook                 \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) IterTimerHook                      \n","(LOW         ) ParamSchedulerHook                 \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","before_val_epoch:\n","(49          ) EMAHook                            \n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","before_val_iter:\n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(NORMAL      ) IterTimerHook                      \n","(NORMAL      ) DetVisualizationHook               \n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","after_val_epoch:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(49          ) EMAHook                            \n","(NORMAL      ) IterTimerHook                      \n","(BELOW_NORMAL) LoggerHook                         \n","(LOW         ) ParamSchedulerHook                 \n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","before_save_checkpoint:\n","(49          ) EMAHook                            \n"," -------------------- \n","after_train:\n","(VERY_LOW    ) CheckpointHook                     \n"," -------------------- \n","before_test_epoch:\n","(49          ) EMAHook                            \n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","before_test_iter:\n","(NORMAL      ) IterTimerHook                      \n"," -------------------- \n","after_test_iter:\n","(NORMAL      ) IterTimerHook                      \n","(NORMAL      ) DetVisualizationHook               \n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","after_test_epoch:\n","(VERY_HIGH   ) RuntimeInfoHook                    \n","(49          ) EMAHook                            \n","(NORMAL      ) IterTimerHook                      \n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","after_run:\n","(BELOW_NORMAL) LoggerHook                         \n"," -------------------- \n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.2.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stem.2.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.main_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.main_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.short_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.short_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.final_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.final_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage1.1.attention.fc.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.main_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.main_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.short_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.short_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.final_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.final_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage2.1.attention.fc.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.main_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.main_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.short_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.short_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.final_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.final_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage3.1.attention.fc.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv2.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.1.conv2.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.main_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.main_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.short_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.short_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.final_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.final_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stage4.2.attention.fc.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.reduce_layers.1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.main_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.short_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.final_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.main_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.short_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.final_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.top_down_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.downsamples.1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.main_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.short_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.final_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.0.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.main_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.short_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.final_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.depthwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.bottom_up_blocks.1.blocks.0.conv2.pointwise_conv.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.2.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- neck.out_convs.2.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.0.1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.1.1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.cls_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.cls_convs.2.1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.0.0.conv is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.0.0.bn is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.0.1.conv is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.0.1.bn is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.1.0.conv is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.1.0.bn is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.1.1.conv is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.1.1.bn is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.2.0.conv is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.2.0.bn is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.2.1.conv is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - bbox_head.reg_convs.2.1.bn is duplicate. It is skipped since bypass_duplicate=True\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.kernel_convs.0.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.kernel_convs.0.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.kernel_convs.0.1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.kernel_convs.0.1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.kernel_convs.1.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.kernel_convs.1.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.kernel_convs.1.1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.kernel_convs.1.1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.kernel_convs.2.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.kernel_convs.2.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.kernel_convs.2.1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.kernel_convs.2.1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_cls.0.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_cls.1.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_cls.2.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_reg.0.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_reg.1.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_reg.2.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_kernel.0.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_kernel.1.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.rtm_kernel.2.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.mask_head.fusion_conv.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.mask_head.stacked_convs.0.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.mask_head.stacked_convs.0.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.mask_head.stacked_convs.1.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.mask_head.stacked_convs.1.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.mask_head.stacked_convs.2.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.mask_head.stacked_convs.2.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.mask_head.stacked_convs.3.bn.weight:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.mask_head.stacked_convs.3.bn.bias:weight_decay=0.0\n","06/11 13:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- bbox_head.mask_head.projection.bias:weight_decay=0.0\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=0.00s)\n","creating index...\n","index created!\n","06/11 13:17:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load backbone. in model from: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth\n","Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/cspnext_rsb_pretrain/cspnext-tiny_imagenet_600e.pth\n","Loads checkpoint by http backend from path: https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet-ins_tiny_8xb32-300e_coco/rtmdet-ins_tiny_8xb32-300e_coco_20221130_151727-ec670f7e.pth\n","The model and loaded state dict do not match exactly\n","\n","size mismatch for bbox_head.rtm_cls.0.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 96, 1, 1]).\n","size mismatch for bbox_head.rtm_cls.0.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n","size mismatch for bbox_head.rtm_cls.1.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 96, 1, 1]).\n","size mismatch for bbox_head.rtm_cls.1.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n","size mismatch for bbox_head.rtm_cls.2.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 96, 1, 1]).\n","size mismatch for bbox_head.rtm_cls.2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n","The model and loaded state dict do not match exactly\n","\n","size mismatch for bbox_head.rtm_cls.0.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 96, 1, 1]).\n","size mismatch for bbox_head.rtm_cls.0.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n","size mismatch for bbox_head.rtm_cls.1.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 96, 1, 1]).\n","size mismatch for bbox_head.rtm_cls.1.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n","size mismatch for bbox_head.rtm_cls.2.weight: copying a param with shape torch.Size([80, 96, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 96, 1, 1]).\n","size mismatch for bbox_head.rtm_cls.2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([1]).\n","06/11 13:17:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet-ins_tiny_8xb32-300e_coco/rtmdet-ins_tiny_8xb32-300e_coco_20221130_151727-ec670f7e.pth\n","06/11 13:17:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n","06/11 13:17:00 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n","06/11 13:17:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat.\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","06/11 13:17:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet-tiny_1xb12-40e_cat_20230611_131644\n","06/11 13:17:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][4/4]  lr: 5.1729e-04  eta: 0:25:16  time: 9.7198  data_time: 8.2315  memory: 7589  loss: 3.3556  loss_cls: 1.8291  loss_bbox: 0.7576  loss_mask: 0.7689\n","06/11 13:18:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet-tiny_1xb12-40e_cat_20230611_131644\n","06/11 13:18:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][4/4]  lr: 1.2069e-03  eta: 0:24:07  time: 9.5247  data_time: 8.0658  memory: 7453  loss: 3.1602  loss_cls: 1.7903  loss_bbox: 0.7558  loss_mask: 0.6141\n","06/11 13:18:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet-tiny_1xb12-40e_cat_20230611_131644\n","06/11 13:18:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][4/4]  lr: 1.8966e-03  eta: 0:23:15  time: 9.4302  data_time: 8.0095  memory: 7496  loss: 3.0117  loss_cls: 1.7590  loss_bbox: 0.7350  loss_mask: 0.5177\n","06/11 13:19:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet-tiny_1xb12-40e_cat_20230611_131644\n","06/11 13:19:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][4/4]  lr: 2.5862e-03  eta: 0:21:55  time: 9.1340  data_time: 7.7197  memory: 7799  loss: 2.8100  loss_cls: 1.6518  loss_bbox: 0.7016  loss_mask: 0.4566\n","06/11 13:19:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet-tiny_1xb12-40e_cat_20230611_131644\n","06/11 13:19:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][4/4]  lr: 3.2759e-03  eta: 0:20:51  time: 8.9383  data_time: 7.5055  memory: 7520  loss: 2.5543  loss_cls: 1.4728  loss_bbox: 0.6672  loss_mask: 0.4144\n","06/11 13:20:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet-tiny_1xb12-40e_cat_20230611_131644\n","06/11 13:20:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][4/4]  lr: 3.9655e-03  eta: 0:20:10  time: 8.9016  data_time: 7.3990  memory: 7717  loss: 2.3485  loss_cls: 1.3339  loss_bbox: 0.6317  loss_mask: 0.3829\n","06/11 13:21:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet-tiny_1xb12-40e_cat_20230611_131644\n","06/11 13:21:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][4/4]  lr: 4.6552e-03  eta: 0:19:36  time: 8.9125  data_time: 7.4286  memory: 7763  loss: 2.1932  loss_cls: 1.2257  loss_bbox: 0.6091  loss_mask: 0.3584\n","06/11 13:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet-tiny_1xb12-40e_cat_20230611_131644\n","06/11 13:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][4/4]  lr: 5.0000e-03  eta: 0:18:58  time: 8.8941  data_time: 7.4271  memory: 7460  loss: 2.0630  loss_cls: 1.1379  loss_bbox: 0.5884  loss_mask: 0.3368\n","06/11 13:22:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet-tiny_1xb12-40e_cat_20230611_131644\n","06/11 13:22:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][4/4]  lr: 5.0000e-03  eta: 0:18:14  time: 8.8249  data_time: 7.3646  memory: 7576  loss: 1.9584  loss_cls: 1.0695  loss_bbox: 0.5694  loss_mask: 0.3195\n","06/11 13:22:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: rtmdet-tiny_1xb12-40e_cat_20230611_131644\n","06/11 13:22:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][4/4]  lr: 5.0000e-03  eta: 0:17:32  time: 8.7713  data_time: 7.3000  memory: 7702  loss: 1.8723  loss_cls: 1.0110  loss_bbox: 0.5544  loss_mask: 0.3068\n","06/11 13:22:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n","Traceback (most recent call last):\n","  File \"/content/mmdetection/tools/train.py\", line 133, in <module>\n","    main()\n","  File \"/content/mmdetection/tools/train.py\", line 129, in main\n","    runner.train()\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/runner.py\", line 1721, in train\n","    model = self.train_loop.run()  # type: ignore\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 102, in run\n","    self.runner.val_loop.run()\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 363, in run\n","    self.run_iter(idx, data_batch)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/runner/loops.py\", line 383, in run_iter\n","    outputs = self.runner.model.val_step(data_batch)\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\", line 133, in val_step\n","    return self._run_forward(data, mode='predict')  # type: ignore\n","  File \"/usr/local/lib/python3.10/dist-packages/mmengine/model/base_model/base_model.py\", line 340, in _run_forward\n","    results = self(**data, mode=mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/mmdet/models/detectors/base.py\", line 94, in forward\n","    return self.predict(inputs, data_samples)\n","  File \"/usr/local/lib/python3.10/dist-packages/mmdet/models/detectors/single_stage.py\", line 110, in predict\n","    results_list = self.bbox_head.predict(\n","  File \"/usr/local/lib/python3.10/dist-packages/mmdet/models/dense_heads/base_dense_head.py\", line 197, in predict\n","    predictions = self.predict_by_feat(\n","  File \"/usr/local/lib/python3.10/dist-packages/mmdet/models/dense_heads/rtmdet_ins_head.py\", line 256, in predict_by_feat\n","    results = self._predict_by_feat_single(\n","  File \"/usr/local/lib/python3.10/dist-packages/mmdet/models/dense_heads/rtmdet_ins_head.py\", line 417, in _predict_by_feat_single\n","    return self._bbox_mask_post_process(\n","  File \"/usr/local/lib/python3.10/dist-packages/mmdet/models/dense_heads/rtmdet_ins_head.py\", line 500, in _bbox_mask_post_process\n","    mask_logits = F.interpolate(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 3919, in interpolate\n","    return torch._C._nn.upsample_bilinear2d(input, output_size, align_corners, scale_factors)\n","RuntimeError: CUDA out of memory. Tried to allocate 23.55 GiB (GPU 0; 14.75 GiB total capacity; 2.63 GiB already allocated; 10.69 GiB free; 2.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"]}]},{"cell_type":"markdown","source":["+ 由于Google colab的IO读取data_time时间很长，训练需要15分钟，实际上在低端显卡1660本地环境上运行大概只需要五分钟\n","+ 由于训练的epoch很短，因此多次运行，mAP可能会有3~4个点的差异"],"metadata":{"id":"-C8PdhzDQTWg"}},{"cell_type":"markdown","source":["## 3.6 推理和验证"],"metadata":{"id":"pKsw5-fCRCQC"}},{"cell_type":"markdown","source":["`--show-dir '/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat/result'`\n","+ 保存分析结果"],"metadata":{"id":"8G0oisws854E"}},{"cell_type":"code","source":["import torch\n","torch.cuda.empty_cache()\n","\n","import os\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""],"metadata":{"id":"iwbD-TUm-DdP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/mmdetection/tools/test.py \\\n","'/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_cat_trick.py'\\\n","'/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat/epoch_40.pth' \\\n","# --show-dir '/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat/result'"],"metadata":{"id":"y_EZCwkjP9QU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["+ 加上会报错：\n","`AssertionError: `binary_marks` must have the same shape with image`\n","\n","+ 不加报错：\n","`RuntimeError: CUDA out of memory. Tried to allocate 6.29 GiB (GPU 0; 14.75 GiB total capacity; 9.48 GiB already allocated; 4.01 GiB free; 9.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","1\n","+ 大概率是库或者配置文件的问题"],"metadata":{"id":"D-zqvItLlpSt"}},{"cell_type":"markdown","source":["## 3.7 可视化结果"],"metadata":{"id":"s0w1jrREBPnx"}},{"cell_type":"markdown","source":["左边是标注框（GT），右边是预测框"],"metadata":{"id":"QFPSVzhdCSZW"}},{"cell_type":"code","source":["import os\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","%matplotlib inline\n","\n","plt.figure(figsize=(20,20))\n","\n","root_path = '/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat/result'\n","image_path_list = os.listdir(root_path)[:4]\n","\n","for i,filename in enumerate(image_path_list):\n","  name = os.path.splitext(filename)[0]\n","  imageFilePath = os.path.join(image_path,filename)\n","  image = Image.open(imageFilePath).convert('RGB')\n","  plt.subplot(4,1,i+1)\n","  plt.imshow(image)\n","  plt.title(filename)\n","plt.tight_layout()"],"metadata":{"id":"SCBxU85DBSPv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.8 可视化后端（tensorboard和wandB）"],"metadata":{"id":"oP_GwG11Cjtn"}},{"cell_type":"markdown","source":["直接加到配置文件最后就行：\n","```python\n","visualizer = dict(vis_backends=[dict(type('LocalVisBackend')), dict(type(WandBVisBackend))])\n","\n","# 以及使用tensorboard后端\n","visualizer = dict(vis_backends=[dict(type('TensorboardVisBackend'))])\n","\n","```"],"metadata":{"id":"ZTD-5DaTCrwy"}},{"cell_type":"markdown","source":["## 3.9 单张图片推理"],"metadata":{"id":"J3qxaHr7DhkY"}},{"cell_type":"code","source":["!python /content/mmdetection/demo/image_demo.py /content/cat_dataset/images/IMG_20210713_213907.jpg\\\n","'/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_cat_trick.py' --weight '/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat/epoch_40.pth' \\\n","--out-dir '/content/drive/MyDrive/OpenMMLab/Exercise_3/output'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8LNoyK8IDkcY","executionInfo":{"status":"ok","timestamp":1686480478288,"user_tz":-480,"elapsed":16138,"user":{"displayName":"黄珊","userId":"02346048459009599635"}},"outputId":"fc6b39a9-145f-43c2-dc31-e56a24956347"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loads checkpoint by local backend from path: /content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat/epoch_40.pth\n","06/11 10:47:48 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n","06/11 10:47:48 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `Visualizer` backend is not initialized because save_dir is None.\n","\u001b[2K/usr/local/lib/python3.10/dist-packages/torch/functional.py:568: UserWarning: \n","torch.meshgrid: in an upcoming release, it will be required to pass the indexing\n","argument. (Triggered internally at  \n","../aten/src/ATen/native/TensorShape.cpp:2228.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","\u001b[2KInference \u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[35m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[35m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[35m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[35m━\u001b[0m\u001b[90m━\u001b[0m  \u001b[36m \u001b[0m\n","\u001b[?25hresults have been saved at /content/drive/MyDrive/OpenMMLab/Exercise_3/output\n"]}]},{"cell_type":"code","source":["from PIL import Image\n","Image.open('/content/drive/MyDrive/OpenMMLab/Exercise_3/output/vis/IMG_20210713_213907.jpg')"],"metadata":{"id":"9CDK9W-fEe7Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.10 基于MMYOLO进行可视化分析"],"metadata":{"id":"lxSlFOxlFqfg"}},{"cell_type":"markdown","source":["+ 可视化分析包括特征图可视化及类似Grad CAM等可视化分析手段，但是由于MMDetection中还没有实现，因此需要直接去调用MMYOLO里的脚本。\n","+ MMYOLO是基于MMDetection开发，所以代码是统一形式的。所以MMDetection的Config是可以直接在MMYOLO中使用的，不用改"],"metadata":{"id":"a90TOlT8Fzdu"}},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGcZ3Bo0Fp-2","executionInfo":{"status":"ok","timestamp":1686481066402,"user_tz":-480,"elapsed":271,"user":{"displayName":"黄珊","userId":"02346048459009599635"}},"outputId":"2cdf3567-1b23-4545-f161-8b3de2615c9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["!rm -rf mmyolo\n","!git clone https://github.com/open-mmlab/mmyolo.git\n","%cd mmyolo\n","%pip install -e ."],"metadata":{"id":"aXH925cbGuCI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","img_path = '/content/drive/MyDrive/OpenMMLab/Exercise_3/output/vis/IMG_20211024_223313.jpg'\n","h,w=img.shape[:2]\n","\n","resized_img= cv2.resize(img,(640,640))\n","cv2.imwrite('/content/resized_img.jpg',resized_img)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qnMBj01cJIg1","executionInfo":{"status":"ok","timestamp":1686481867892,"user_tz":-480,"elapsed":482,"user":{"displayName":"黄珊","userId":"02346048459009599635"}},"outputId":"919a97ed-3054-4359-d435-93c9415ab409"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","source":["### 3.10.1 可视化backbone的三个通道"],"metadata":{"id":"HkxHU5DeJzi0"}},{"cell_type":"code","source":["!python /content/mmyolo/demo/featmap_vis_demo.py /content/resized_img.jpg \\\n","/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_cat_trick.py \\\n","/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat/epoch_40.pth \\\n","--target-layers backbone\\\n","--channel-reduction squeeze_mean"],"metadata":{"id":"4YCHDzcnJxm_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image.open('/content/mmyolo/output/resized_img.jpg')"],"metadata":{"id":"04CokLIWK95A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.10.2 可视化neck的三个通道"],"metadata":{"id":"MX87QAUVLlaa"}},{"cell_type":"code","source":["!python /content/mmyolo/demo/featmap_vis_demo.py /content/resized_img.jpg \\\n","/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_cat_trick.py \\\n","/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat/epoch_40.pth \\\n","--target-layers neck\\\n","--channel-reduction squeeze_mean\n","\n","Image.open('/content/mmyolo/output/resized_img.jpg')"],"metadata":{"id":"Ta9_9qX1LjoN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3.10.3 Grad-Based CAM可视化"],"metadata":{"id":"wh58_CqtMmkg"}},{"cell_type":"markdown","source":["由于目标检测的特殊性，这里实际可视化的并不是CAM而是Grad Box AM，使用前需安装grad-cam库"],"metadata":{"id":"r04xGVF2MsK8"}},{"cell_type":"code","source":["!pip install \"grad-cam\""],"metadata":{"id":"c2wTFSUKNVZL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["neck输出的最小输出特征图的Grad CAM"],"metadata":{"id":"hNun--pGO4hf"}},{"cell_type":"code","source":["!python /content/mmyolo/demo/boxam_vis_demo.py /content/resized_img.jpg \\\n","/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_cat_trick.py \\\n","/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat/epoch_40.pth \\\n","--target-layers neck.out_convs[2]\\\n","\n","Image.open('/content/mmyolo/output/resized_img.jpg')"],"metadata":{"id":"Pt3yH02mOmmv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["neck输出的最大输出特征图的Grad CAM"],"metadata":{"id":"f1M3i6BVO-mn"}},{"cell_type":"code","source":["!python /content/mmyolo/demo/boxam_vis_demo.py /content/resized_img.jpg \\\n","/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_cat_trick.py \\\n","/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat/epoch_40.pth \\\n","--target-layers neck.out_convs[0]\n","\n","# Image.open('/content/mmyolo/output/resized_img.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DTcq_KNQPFxI","executionInfo":{"status":"ok","timestamp":1686483353437,"user_tz":-480,"elapsed":8275,"user":{"displayName":"黄珊","userId":"02346048459009599635"}},"outputId":"2c70d978-a7e9-4f0e-839c-80272c2c7241"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["The algorithm currently used is rtmdet\n","Loads checkpoint by local backend from path: /content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat/epoch_40.pth\n","[                                                  ] 0/1, elapsed: 0s, ETA:Traceback (most recent call last):\n","  File \"/content/mmyolo/demo/boxam_vis_demo.py\", line 276, in <module>\n","    main()\n","  File \"/content/mmyolo/demo/boxam_vis_demo.py\", line 212, in main\n","    result = model_wrapper()[0]\n","  File \"/content/mmyolo/mmyolo/utils/boxam_utils.py\", line 222, in __call__\n","    self.detector.bbox_head.head_module.training = False\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1185, in __getattr__\n","    raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n","AttributeError: 'RTMDetInsSepBNHead' object has no attribute 'head_module'. Did you mean: 'add_module'?\n"]}]},{"cell_type":"markdown","source":["# 4.气球数据集"],"metadata":{"id":"_Bc_Avv7lpr0"}},{"cell_type":"markdown","source":["## 4.1 数据和配置修改"],"metadata":{"id":"knMzROSl_Jc1"}},{"cell_type":"markdown","source":["其实也可以不挂载到google云的，这里有那种可以直接下载的链接啊。。。"],"metadata":{"id":"ZnW6mViMmiLg"}},{"cell_type":"code","source":["!rm -rf balloon_dataset*\n","%cd /content\n","!wget https://download.openmmlab.com/mmyolo/data/balloon_dataset.zip\n","!unzip balloon_dataset.zip -d balloon_dataset && rm balloon_dataset.zip"],"metadata":{"id":"0jq2LEOWloeG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv /content/balloon_dataset/balloon/train/via_region_data.json /content/balloon_dataset/balloon/train.json"],"metadata":{"id":"9W9wqo5dASNu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv /content/balloon_dataset/balloon/val/via_region_data.json /content/balloon_dataset/balloon/val.json"],"metadata":{"id":"ge-sPEZEApW-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["修改用于气球的配置文件，也是个单类目标检测，其实只要改数据路径就行"],"metadata":{"id":"X4dh4Dmums4y"}},{"cell_type":"markdown","source":["## 4.2 数据集格式转为COCO"],"metadata":{"id":"VZ3xXzQ7RUuR"}},{"cell_type":"code","source":["import os.path as osp\n","\n","import mmcv\n","\n","from mmengine.fileio import dump, load\n","from mmengine.utils import track_iter_progress\n","\n","\n","def convert_balloon_to_coco(ann_file, out_file, image_prefix):\n","    data_infos = load(ann_file)\n","\n","    annotations = []\n","    images = []\n","    obj_count = 0\n","    for idx, v in enumerate(track_iter_progress(data_infos.values())):\n","        filename = v['filename']\n","        img_path = osp.join(image_prefix, filename)\n","        height, width = mmcv.imread(img_path).shape[:2]\n","\n","        images.append(\n","            dict(id=idx, file_name=filename, height=height, width=width))\n","\n","        for _, obj in v['regions'].items():\n","            assert not obj['region_attributes']\n","            obj = obj['shape_attributes']\n","            px = obj['all_points_x']\n","            py = obj['all_points_y']\n","            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n","            poly = [p for x in poly for p in x]\n","\n","            x_min, y_min, x_max, y_max = (min(px), min(py), max(px), max(py))\n","\n","            data_anno = dict(\n","                image_id=idx,\n","                id=obj_count,\n","                category_id=0,\n","                bbox=[x_min, y_min, x_max - x_min, y_max - y_min],\n","                area=(x_max - x_min) * (y_max - y_min),\n","                segmentation=[poly],\n","                iscrowd=0)\n","            annotations.append(data_anno)\n","            obj_count += 1\n","\n","    coco_format_json = dict(\n","        images=images,\n","        annotations=annotations,\n","        categories=[{\n","            'id': 0,\n","            'name': 'balloon'\n","        }])\n","    dump(coco_format_json, out_file)\n","\n","\n","if __name__ == '__main__':\n","    convert_balloon_to_coco(ann_file='/content/balloon_dataset/balloon/train.json',\n","                out_file='/content/balloon_dataset/balloon/train_coco.json',\n","                image_prefix='/content/balloon_dataset/balloon/train')\n","    convert_balloon_to_coco(ann_file='/content/balloon_dataset/balloon/val.json',\n","                out_file='/content/balloon_dataset/balloon/val_coco.json',\n","                image_prefix='/content/balloon_dataset/balloon/val')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S2m2DTXTRZ-l","executionInfo":{"status":"ok","timestamp":1686483998506,"user_tz":-480,"elapsed":2491,"user":{"displayName":"黄珊","userId":"02346048459009599635"}},"outputId":"69b5b464-2c2e-49ac-f878-861777a582e2"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 61/61, 30.6 task/s, elapsed: 2s, ETA:     0s\n","[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 13/13, 34.7 task/s, elapsed: 0s, ETA:     0s\n"]}]},{"cell_type":"code","source":["config_ballon = \"\"\"\n","_base_='/content/mmdetection/configs/rtmdet/rtmdet-ins_tiny_8xb32-300e_coco.py'\n","\n","train_batch_size_per_gpu=4\n","train_num_workers=2\n","\n","val_batch_size_per_gpu=1\n","val_num_workers=1\n","\n","num_classes=1\n","\n","model =dict(\n","  backbone = dict(frozen_stages=4),\n","  bbox_head=dict(dict(num_classes=num_classes))\n",")\n","\n","base_lr = train_batch_size_per_gpu*0.04/(32*8)\n","\n","max_epochs=40\n","num_epochs_stage2=5\n","\n","load_from = 'https://download.openmmlab.com/mmdetection/v3.0/rtmdet/rtmdet-ins_tiny_8xb32-300e_coco/rtmdet-ins_tiny_8xb32-300e_coco_20221130_151727-ec670f7e.pth'\n","data_root = '/content/balloon_dataset/balloon/'\n","\n","metainfo={\n","  'classes':('balloon',),\n","  'palette':[(220,20,60),]\n","}\n","\n","train_dataloader = dict(\n","    batch_size=train_batch_size_per_gpu,\n","    num_workers=train_num_workers,\n","    pin_memory=True,\n","    dataset=dict(\n","        data_root=data_root,\n","        metainfo=metainfo,\n","        data_prefix=dict(img='train/'),\n","        ann_file='train_coco.json'\n","    )\n",")\n","\n","val_dataloader = dict(\n","    batch_size=val_batch_size_per_gpu,\n","    num_workers=val_num_workers,\n","    dataset=dict(\n","        data_root=data_root,\n","        metainfo=metainfo,\n","        data_prefix=dict(img='val/'),\n","        ann_file='val_coco.json'\n","   )\n",")\n","test_dataloader = val_dataloader\n","\n","param_scheduler = [\n","    dict(\n","        type='LinearLR',\n","        start_factor=1.0e-5,\n","        by_epoch=False,\n","        begin=0,\n","        end=30),\n","    dict(\n","        # use cosine lr from 10 to 20 epoch\n","        type='CosineAnnealingLR',\n","        eta_min=base_lr * 0.05,\n","        begin=max_epochs // 2, \n","        end=max_epochs,\n","        T_max=max_epochs // 2,\n","        by_epoch=True,\n","        convert_to_iter_based=True),\n","]\n","optim_wrapper = dict(optimizer=dict(lr=base_lr))\n","\n","_base_.custom_hooks[1].switch_epoch = max_epochs-num_epochs_stage2\n","\n","val_evaluator = dict(ann_file=data_root + 'val_coco.json')\n","test_evaluator=val_evaluator\n","\n","default_hooks = dict(\n","    checkpoint=dict(interval=10,max_keep_ckpts=2, save_best='auto'),\n","    logger=dict(type='LoggerHook', interval=5))\n","train_cfg= dict(max_epochs=max_epochs, val_interval=10)\n","\n","\"\"\""],"metadata":{"executionInfo":{"status":"ok","timestamp":1686484234453,"user_tz":-480,"elapsed":6,"user":{"displayName":"黄珊","userId":"02346048459009599635"}},"id":"8k90f1x0nJoY"},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_balloon.py','w') as f:\n","  f.write(config_ballon)"],"metadata":{"id":"OLQe4s8a-40v","executionInfo":{"status":"ok","timestamp":1686484235900,"user_tz":-480,"elapsed":7,"user":{"displayName":"黄珊","userId":"02346048459009599635"}}},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 训练测试"],"metadata":{"id":"Nifh_j5Z_N8t"}},{"cell_type":"markdown","source":["### 4.2.1训练"],"metadata":{"id":"Jwi9N69hWjRD"}},{"cell_type":"code","source":["!python /content/mmdetection/tools/train.py \\\n","'/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_balloon.py'\\\n","--work-dir '/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_balloon'"],"metadata":{"id":"_Z4OrGeL_E6H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.2.2测试"],"metadata":{"id":"Z2yHHKGXWlQp"}},{"cell_type":"markdown","source":["show-dir 依然报错 `AssertionError: `binary_marks` must have the same shape with image`"],"metadata":{"id":"7RukkjBsWvDE"}},{"cell_type":"code","source":["!python /content/mmdetection/tools/test.py \\\n","'/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_balloon.py'\\\n","'/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_balloon/best_coco_bbox_mAP_epoch_40.pth' \\\n","# --show-dir '/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_cat/result'"],"metadata":{"id":"ONVRCE4p_bno"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.2.3单张图片推理"],"metadata":{"id":"dHUCUVe3W9MS"}},{"cell_type":"code","source":["!python /content/mmdetection/demo/image_demo.py /content/drive/MyDrive/OpenMMLab/Exercise_3/test_balloon.jpeg\\\n","/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_balloon.py --weight /content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_balloon/best_coco_bbox_mAP_epoch_40.pth \\\n","--out-dir /content/drive/MyDrive/OpenMMLab/Exercise_3/output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1S71Fw23Wijk","executionInfo":{"status":"ok","timestamp":1686485578463,"user_tz":-480,"elapsed":58104,"user":{"displayName":"黄珊","userId":"02346048459009599635"}},"outputId":"07dab308-4c09-47ea-eb95-8c64fd6b2139"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Loads checkpoint by local backend from path: /content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_balloon/best_coco_bbox_mAP_epoch_40.pth\n","06/11 12:12:08 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmdet\" in the \"function\" registry tree. As a workaround, the current \"function\" registry in \"mmengine\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmdet\" is a correct scope, or whether the registry is initialized.\n","06/11 12:12:08 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - `Visualizer` backend is not initialized because save_dir is None.\n","\u001b[2K/usr/local/lib/python3.10/dist-packages/torch/functional.py:568: UserWarning: \n","torch.meshgrid: in an upcoming release, it will be required to pass the indexing\n","argument. (Triggered internally at  \n","../aten/src/ATen/native/TensorShape.cpp:2228.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","\u001b[2KInference \u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[35m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[35m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[35m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[90m━\u001b[0m\u001b[35m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m\u001b[91m━\u001b[0m  \u001b[36m \u001b[0m\n","\u001b[?25hresults have been saved at /content/drive/MyDrive/OpenMMLab/Exercise_3/output\n"]}]},{"cell_type":"markdown","source":["### 4.2.4特征图可视化"],"metadata":{"id":"LMRSUfC0X6WF"}},{"cell_type":"code","source":["!python /content/mmyolo/demo/featmap_vis_demo.py /content/drive/MyDrive/OpenMMLab/Exercise_3/test_balloonAM.jpeg \\\n","/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_balloon.py \\\n","/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_balloon/best_coco_bbox_mAP_epoch_40.pth \\\n","--target-layers neck\\\n","--channel-reduction squeeze_mean\\\n","--out-dir /content/drive/MyDrive/OpenMMLab/Exercise_3/output\n","\n","Image.open('/content/drive/MyDrive/OpenMMLab/Exercise_3/output/test_balloonAM.jpeg')"],"metadata":{"id":"FzuMTmztXhLs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4.2.5Box AM 可视化"],"metadata":{"id":"P80mcikXX6QY"}},{"cell_type":"code","source":["!python /content/mmyolo/demo/boxam_vis_demo.py /content/drive/MyDrive/OpenMMLab/Exercise_3/test_balloonCAM.jpeg \\\n","/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_balloon.py \\\n","/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_balloon/best_coco_bbox_mAP_epoch_40.pth \\\n","--target-layers neck.out_convs[2]\\\n","--out-dir /content/drive/MyDrive/OpenMMLab/Exercise_3/output\n","\n","Image.open('/content/drive/MyDrive/OpenMMLab/Exercise_3/test_balloonCAM.jpeg')"],"metadata":{"id":"80LwcaGiYLMU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python /content/mmyolo/demo/boxam_vis_demo.py /content/drive/MyDrive/OpenMMLab/Exercise_3/test_balloonCAM.jpeg \\\n","/content/drive/MyDrive/OpenMMLab/Exercise_3/rtmdet-tiny_1xb12-40e_balloon.py \\\n","/content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_balloon/best_coco_bbox_mAP_epoch_40.pth \\\n","--target-layers neck\\\n","--out-dir /content/drive/MyDrive/OpenMMLab/Exercise_3/output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wD31x2UoaBvq","executionInfo":{"status":"ok","timestamp":1686486354488,"user_tz":-480,"elapsed":9095,"user":{"displayName":"黄珊","userId":"02346048459009599635"}},"outputId":"db26b740-3712-4635-c19e-c90495a29278"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["The algorithm currently used is rtmdet\n","Loads checkpoint by local backend from path: /content/drive/MyDrive/OpenMMLab/workdir/rtmdet_tiny_balloon/best_coco_bbox_mAP_epoch_40.pth\n","[                                                  ] 0/1, elapsed: 0s, ETA:Traceback (most recent call last):\n","  File \"/content/mmyolo/demo/boxam_vis_demo.py\", line 276, in <module>\n","    main()\n","  File \"/content/mmyolo/demo/boxam_vis_demo.py\", line 212, in main\n","    result = model_wrapper()[0]\n","  File \"/content/mmyolo/mmyolo/utils/boxam_utils.py\", line 222, in __call__\n","    self.detector.bbox_head.head_module.training = False\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1185, in __getattr__\n","    raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n","AttributeError: 'RTMDetInsSepBNHead' object has no attribute 'head_module'. Did you mean: 'add_module'?\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"sHyvhPd-aolN"},"execution_count":null,"outputs":[]}]}