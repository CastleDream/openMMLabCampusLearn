{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14c3526a-d6b3-4203-b703-2977613b56c9",
   "metadata": {},
   "source": [
    "# 1. bce2d和boundary_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dffd8b8-1c56-4c6e-a0c5-3b507c6a0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02b6be3c-c2b0-44f6-8d89-246d7a36a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce2d(input, target):\n",
    "        \"\"\"To calculate weighted cross-entropy of two binary boundary map,\n",
    "        input and target are both binary boundary map.\n",
    "\n",
    "        Args:\n",
    "        input(Tensor): pred binary boundary map.\n",
    "        target(Tensor): ground truth binary boundary map generated by using Sobel\n",
    "            filter and threshold on ground truth segmentation mask.\n",
    "        \"\"\"\n",
    "        print(f\"input.shape: {input.shape}\")\n",
    "        log_p = input.transpose(1, 2).transpose(2, 3).contiguous().view(1, -1)\n",
    "        print(f\"log_p.shape: {log_p.shape}\")\n",
    "        target_t = target.transpose(1,2).transpose(2,3).contiguous().view(1, -1)\n",
    "        target_trans = target_t.clone()\n",
    "\n",
    "        pos_index = (target_t == 1)\n",
    "        neg_index = (target_t == 0)\n",
    "        ignore_index = (target_t > 1)\n",
    "\n",
    "        target_trans[pos_index] = 1\n",
    "        target_trans[neg_index] = 0\n",
    "\n",
    "        pos_index = pos_index.data.cpu().numpy().astype(bool)\n",
    "        neg_index = neg_index.data.cpu().numpy().astype(bool)\n",
    "        ignore_index = ignore_index.data.cpu().numpy().astype(bool)\n",
    "\n",
    "        weight = torch.Tensor(log_p.size()).fill_(0)\n",
    "        weight = weight.numpy()\n",
    "        pos_num = pos_index.sum()\n",
    "        neg_num = neg_index.sum()\n",
    "        sum_num = pos_num + neg_num\n",
    "        weight[pos_index] = neg_num * 1.0 / sum_num\n",
    "        weight[neg_index] = pos_num * 1.0 / sum_num\n",
    "\n",
    "        weight[ignore_index] = 0\n",
    "\n",
    "        weight = torch.from_numpy(weight)\n",
    "        weight = weight\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            log_p, target_t, weight, size_average=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4488017-eed5-4728-b531-66d8db6fc44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/XuJiacong/PIDNet/blob/main/utils/criterion.py#L122\n",
    "def weighted_bce(bd_pre, target):\n",
    "    n, c, h, w = bd_pre.size()\n",
    "    log_p = bd_pre.permute(0,2,3,1).contiguous().view(1, -1)\n",
    "    target_t = target.view(1, -1)\n",
    "\n",
    "    pos_index = (target_t == 1)\n",
    "    neg_index = (target_t == 0)\n",
    "\n",
    "    weight = torch.zeros_like(log_p)\n",
    "    pos_num = pos_index.sum()\n",
    "    neg_num = neg_index.sum()\n",
    "    sum_num = pos_num + neg_num\n",
    "    weight[pos_index] = neg_num * 1.0 / sum_num\n",
    "    weight[neg_index] = pos_num * 1.0 / sum_num\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(log_p, target_t, weight, reduction='mean')\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c22611d-b5e6-483c-9002-bee7558b8f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 16, 16])\n",
      "input.shape: torch.Size([2, 1, 16, 16])\n",
      "log_p.shape: torch.Size([1, 512])\n",
      "tensor(0.0991)\n",
      "tensor(0.0991)\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2,1,16,16)\n",
    "a[:,:,5,:] = 1\n",
    "a[:,:,1,:] = 3\n",
    "# print(a.shape)\n",
    "# print(a)\n",
    "pre = torch.randn(2,1,16,16)\n",
    "print(pre.shape)\n",
    "\n",
    "print(bce2d(pre, a))\n",
    "print(weighted_bce(pre, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2691f0ad-1d54-47f4-aa6c-f0c1ed0bcf20",
   "metadata": {},
   "source": [
    "确实结果是一样的。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e5c9fe4-9726-4b40-951d-c9fd64e3e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boundary Loss 原理与代码解析 https://blog.csdn.net/ooooocj/article/details/126560722\n",
    "# 和这个好像不是一个东西\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import einsum\n",
    "from torch import Tensor\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "from typing import Any, Callable, Iterable, List, Set, Tuple, TypeVar, Union\n",
    " \n",
    " \n",
    "# switch between representations\n",
    "def probs2class(probs: Tensor) -> Tensor:\n",
    "    b, _, w, h = probs.shape  # type: Tuple[int, int, int, int]\n",
    "    assert simplex(probs)\n",
    " \n",
    "    res = probs.argmax(dim=1)\n",
    "    assert res.shape == (b, w, h)\n",
    " \n",
    "    return res\n",
    " \n",
    "def probs2one_hot(probs: Tensor) -> Tensor:\n",
    "    _, C, _, _ = probs.shape\n",
    "    assert simplex(probs)\n",
    " \n",
    "    res = class2one_hot(probs2class(probs), C)\n",
    "    assert res.shape == probs.shape\n",
    "    assert one_hot(res)\n",
    " \n",
    "    return res\n",
    " \n",
    "def class2one_hot(seg: Tensor, C: int) -> Tensor:\n",
    "    if len(seg.shape) == 2:  # Only w, h, used by the dataloader\n",
    "        seg = seg.unsqueeze(dim=0)\n",
    "    assert sset(seg, list(range(C)))\n",
    " \n",
    "    b, w, h = seg.shape  # type: Tuple[int, int, int]\n",
    " \n",
    "    res = torch.stack([seg == c for c in range(C)], dim=1).type(torch.int32)\n",
    "    assert res.shape == (b, C, w, h)\n",
    "    assert one_hot(res)\n",
    " \n",
    "    return res\n",
    " \n",
    "def one_hot2dist(seg: np.ndarray) -> np.ndarray:\n",
    "    assert one_hot(torch.Tensor(seg), axis=0)\n",
    "    C: int = len(seg)\n",
    " \n",
    "    res = np.zeros_like(seg)\n",
    "    # res = res.astype(np.float64)\n",
    "    for c in range(C):\n",
    "        posmask = seg[c].astype(np.bool)\n",
    " \n",
    "        if posmask.any():\n",
    "            negmask = ~posmask\n",
    "            res[c] = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "    return res\n",
    " \n",
    "def simplex(t: Tensor, axis=1) -> bool:\n",
    "    _sum = t.sum(axis).type(torch.float32)\n",
    "    _ones = torch.ones_like(_sum, dtype=torch.float32)\n",
    "    return torch.allclose(_sum, _ones)\n",
    " \n",
    "def one_hot(t: Tensor, axis=1) -> bool:\n",
    "    return simplex(t, axis) and sset(t, [0, 1])\n",
    " \n",
    "    # Assert utils\n",
    " \n",
    " \n",
    "def uniq(a: Tensor) -> Set:\n",
    "    return set(torch.unique(a.cpu()).numpy())\n",
    " \n",
    "def sset(a: Tensor, sub: Iterable) -> bool:\n",
    "    return uniq(a).issubset(sub)\n",
    " \n",
    "class SurfaceLoss():\n",
    "    def __init__(self):\n",
    "        # Self.idc is used to filter out some classes of the target mask. Use fancy indexing\n",
    "        self.idc: List[int] = [1]  # 这里忽略背景类  https://github.com/LIVIAETS/surface-loss/issues/3\n",
    " \n",
    "    # probs: bcwh, dist_maps: bcwh\n",
    "    def __call__(self, probs: Tensor, dist_maps: Tensor, _: Tensor) -> Tensor:\n",
    "        assert simplex(probs)\n",
    "        assert not one_hot(dist_maps)\n",
    " \n",
    "        pc = probs[:, self.idc, ...].type(torch.float32)\n",
    "        dc = dist_maps[:, self.idc, ...].type(torch.float32)\n",
    " \n",
    "        multiplied = einsum(\"bcwh,bcwh->bcwh\", pc, dc)\n",
    " \n",
    "        loss = multiplied.mean()\n",
    " \n",
    "        return loss\n",
    " \n",
    "def test(data,logits):\n",
    "    # data = torch.tensor([[[0, 0, 0, 0, 0, 0, 0],\n",
    "    #                       [0, 1, 1, 0, 0, 0, 0],\n",
    "    #                       [0, 1, 1, 0, 0, 0, 0],\n",
    "    #                       [0, 0, 0, 0, 0, 0, 0]]])  # (b, h, w)->(1,4,7)\n",
    "    data2 = class2one_hot(data, 2)  # (b, num_class, h, w): (1,2,4,7)\n",
    "    data2 = data2[0].numpy()  # (2,4,7)\n",
    "    data3 = one_hot2dist(data2)  # bcwh\n",
    "    # logits = torch.tensor([[[0, 0, 0, 0, 0, 0, 0],\n",
    "    #                         [0, 1, 1, 1, 1, 1, 0],\n",
    "    #                         [0, 1, 1, 0, 0, 0, 0],\n",
    "    #                         [0, 0, 0, 0, 0, 0, 0]]])  # (b, h, w)\n",
    "\n",
    "    logits = class2one_hot(logits, 2)\n",
    "    Loss = SurfaceLoss()\n",
    "    data3 = torch.tensor(data3).unsqueeze(0)\n",
    "    res = Loss(logits, data3, None)\n",
    "    print('loss:', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20602891-058b-480f-bd2a-d733bbd98e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 16])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qc/18zs860s79jg5k6p1pdwplpc0000gn/T/ipykernel_68550/1241455817.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/qc/18zs860s79jg5k6p1pdwplpc0000gn/T/ipykernel_68550/143048662.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(data, logits)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m#                       [0, 1, 1, 0, 0, 0, 0],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m#                       [0, 0, 0, 0, 0, 0, 0]]])  # (b, h, w)->(1,4,7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass2one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, num_class, h, w): (1,2,4,7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (2,4,7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mdata3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot2dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# bcwh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/qc/18zs860s79jg5k6p1pdwplpc0000gn/T/ipykernel_68550/143048662.py\u001b[0m in \u001b[0;36mclass2one_hot\u001b[0;34m(seg, C)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only w, h, used by the dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0msset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m  \u001b[0;31m# type: Tuple[int, int, int]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(pre[1].shape)\n",
    "test(pre[1],a[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ab15b-fee6-472e-b88c-41bd6760b768",
   "metadata": {},
   "source": [
    "# 2. InverseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab5faf1-5b71-48c7-a495-01195f6badf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 4, 4])\n",
      "tensor([[[2, 3, 3, 2],\n",
      "         [8, 4, 3, 4],\n",
      "         [7, 9, 7, 7],\n",
      "         [1, 9, 9, 7]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "pred = torch.rand((1, 10, 4, 4))\n",
    "target = torch.randint(0, 10, (1, 4, 4))\n",
    "print(pred.shape)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a46ac98-916f-4d77-b216-803d0c293882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b955fc-e08e-4c03-a5a8-7e77f0e58302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 4, 4])\n",
      "torch.Size([8, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "logits = torch.rand(8, 3, 4, 4)\n",
    "labels = (torch.rand(8, 4, 4) * 3).long()\n",
    "print(logits.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae4844e-707e-4eb2-99c6-aeedb604e3f0",
   "metadata": {},
   "source": [
    "我的跟其他的似乎不是很一样，其他都是对Segmentation的mask进行loss的计算，\n",
    "\n",
    "这个是对两个boundary map进行计算的。。。不一样，这个只有一类前景，不是多类的前景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd77c008-dc13-4db0-be7a-927dac3edb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred is:tensor([[[1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]]), \n",
      " target is tensor([[[1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.],\n",
      "         [1., 0., 0., 0.]]])\n",
      "pred is:tensor([[[0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]]), \n",
      " target is tensor([[[0., 1., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 1., 0., 0.]]])\n",
      "pred is:tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0.]]]), \n",
      " target is tensor([[[0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "pred = torch.zeros(3, 1, 4, 4)\n",
    "target = torch.zeros(3, 1, 4, 4)\n",
    "\n",
    "for i in range(3):\n",
    "    pred[i, 0, i, :] = 1\n",
    "    target[i, 0, :, i] = 1\n",
    "    print(f\"pred is:{pred[i]}, \\n target is {target[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ccada4b-cd0d-4585-b7c1-5e92583feee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 4, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "564c36ea-470c-4f59-880a-df8498af5d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49671900-8419-4f27-a57d-a4da4bb71d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('distance_measures_regressor.pth',\n",
       " <http.client.HTTPMessage at 0x7fb073291210>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "pretraind_model_url = 'https://github.com/Qualcomm-AI-research/InverseForm/releases/download/v1.0/distance_measures_regressor.pth'\n",
    "inverseNet_path = 'distance_measures_regressor.pth'\n",
    "urllib.request.urlretrieve(pretraind_model_url, inverseNet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b71563a3-da54-48c6-ac84-2c76b5073c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/Qualcomm-AI-research/InverseForm/releases/download/v1.0/distance_measures_regressor.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 402M/402M [00:17<00:00, 22.7MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "repo = \"https://github.com/Qualcomm-AI-research/InverseForm/\"\n",
    "download_folder=\"releases/download/v1.0/distance_measures_regressor.pth\"\n",
    "pretraind_model_url=repo+download_folder\n",
    "print(pretraind_model_url)\n",
    "\n",
    "response = requests.get(pretraind_model_url, stream=True)\n",
    "total_size_in_bytes= int(response.headers.get('content-length', 0))\n",
    "block_size = 1024 #1 Kibibyte\n",
    "progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True)\n",
    "with open(inverseNet_path, 'wb') as file:\n",
    "    for data in response.iter_content(block_size):\n",
    "        progress_bar.update(len(data))\n",
    "        file.write(data)\n",
    "progress_bar.close()\n",
    "if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "    print(\"ERROR, something went wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ef83af-366d-4ac4-9cef-12bed2137df3",
   "metadata": {},
   "source": [
    "参考：https://stackoverflow.com/questions/37573483/progress-bar-while-download-file-over-http-with-requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ecd2c6a-f06c-42c6-9186-901af2495750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"./checkpoints\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9bb3aac-fcd8-4ac3-9f6a-eb7084042517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/huangshan/Documents/DailyStudy/openMMLabCampusLearn/PR/PR3',\n",
       " '/Users/huangshan/Documents/software/miniconda3/miniconda3/envs/py37/lib/python37.zip',\n",
       " '/Users/huangshan/Documents/software/miniconda3/miniconda3/envs/py37/lib/python3.7',\n",
       " '/Users/huangshan/Documents/software/miniconda3/miniconda3/envs/py37/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Users/huangshan/Documents/software/miniconda3/miniconda3/envs/py37/lib/python3.7/site-packages',\n",
       " '/Users/huangshan/Documents/DailyStudy/openMMLabCampusLearn/selfExercise/mmsegmentation',\n",
       " '/Users/huangshan/Documents/DailyStudy/openMMLabCampusLearn/selfExercise/mmdetection',\n",
       " '/Users/huangshan/Documents/software/miniconda3/miniconda3/envs/py37/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/huangshan/.ipython']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7898ff0-bc1a-4cb0-b352-cb3e38d366ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/huangshan/Documents/DailyStudy/mmsegmentation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
